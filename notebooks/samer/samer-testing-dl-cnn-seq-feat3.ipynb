{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf5954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8edf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../../raw_data/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff912c9d",
   "metadata": {},
   "source": [
    "## Trying the Poteaux csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03d0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv(tableau, files):\n",
    "    dfs = []\n",
    "\n",
    "    for i in files:\n",
    "        csv_path = os.path.join(base_dir, f\"maquette{i}\", f\"{tableau}{i}.csv\")\n",
    "        if os.path.exists(csv_path):\n",
    "            # Cherche la ligne d'en-tête réelle\n",
    "            with open(csv_path, encoding=\"utf-8\") as f:\n",
    "                for idx, line in enumerate(f):\n",
    "                    if line.startswith(\"Id;\"):\n",
    "                        header_row = idx\n",
    "                        break\n",
    "            try:\n",
    "                df = pd.read_csv(csv_path, sep=';', decimal=\",\", header=header_row)\n",
    "                dfs.append(df)\n",
    "                print(f\"Chargé : {csv_path} ({df.shape[0]} lignes, {df.shape[1]} colonnes)\")\n",
    "                #print(df.head())\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur de parsing : {csv_path} -> {e}\")\n",
    "        else:\n",
    "            print(f\"Fichier non trouvé : {csv_path}\")\n",
    "\n",
    "    if dfs:\n",
    "        dfs_concat = pd.concat(dfs, ignore_index=True)\n",
    "        print(f\"Total concaténé : {dfs_concat.shape[0]} lignes, {dfs_concat.shape[1]} colonnes\")\n",
    "    else:\n",
    "        dfs_concat = pd.DataFrame()\n",
    "        print(\"Aucun fichier murs.csv trouvé.\")\n",
    "\n",
    "    return dfs_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776d7051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargé : ../../raw_data/maquette1/murs1.csv (1589 lignes, 146 colonnes)\n",
      "Chargé : ../../raw_data/maquette2/murs2.csv (215 lignes, 149 colonnes)\n",
      "Chargé : ../../raw_data/maquette3/murs3.csv (203 lignes, 143 colonnes)\n",
      "Chargé : ../../raw_data/maquette4/murs4.csv (312 lignes, 96 colonnes)\n",
      "Chargé : ../../raw_data/maquette5/murs5.csv (345 lignes, 94 colonnes)\n",
      "Chargé : ../../raw_data/maquette6/murs6.csv (203 lignes, 91 colonnes)\n",
      "Chargé : ../../raw_data/maquette11/murs11.csv (121 lignes, 115 colonnes)\n",
      "Chargé : ../../raw_data/maquette12/murs12.csv (121 lignes, 118 colonnes)\n",
      "Chargé : ../../raw_data/maquette13/murs13.csv (797 lignes, 104 colonnes)\n",
      "Chargé : ../../raw_data/maquette14/murs14.csv (3518 lignes, 107 colonnes)\n",
      "Chargé : ../../raw_data/maquette15/murs15.csv (1228 lignes, 113 colonnes)\n",
      "Chargé : ../../raw_data/maquette16/murs16.csv (1088 lignes, 87 colonnes)\n",
      "Chargé : ../../raw_data/maquette17/murs17.csv (84 lignes, 86 colonnes)\n",
      "Chargé : ../../raw_data/maquette18/murs18.csv (1743 lignes, 91 colonnes)\n",
      "Chargé : ../../raw_data/maquette19/murs19.csv (2018 lignes, 91 colonnes)\n",
      "Chargé : ../../raw_data/maquette20/murs20.csv (48 lignes, 86 colonnes)\n",
      "Total concaténé : 13633 lignes, 258 colonnes\n"
     ]
    }
   ],
   "source": [
    "files = [1,2,3,4,5,6,11,12,13,14,15,16,17,18,19,20]\n",
    "dfs_concat = import_csv('murs', files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479be204",
   "metadata": {},
   "source": [
    "### FEATURES SELECTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0daeade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = dfs_concat.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ea4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = dfs_concat.isnull().sum() * 100 / len(dfs_concat)\n",
    "\n",
    "missing_value_df = pd.DataFrame({'column_name': dfs_concat.columns,\n",
    "                                 'percent_missing': percent_missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59130d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = missing_value_df.sort_values('percent_missing',\n",
    "                                            ascending=False)['column_name'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1441b2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " '011EC_Lot',\n",
       " '012EC_Ouvrage',\n",
       " '013EC_Localisation',\n",
       " '014EC_Mode Constructif',\n",
       " 'Nom',\n",
       " 'Hauteur',\n",
       " 'Epaisseur',\n",
       " 'AI',\n",
       " 'AS',\n",
       " 'Sols en intersection',\n",
       " 'Sols coupés (u)',\n",
       " 'Sols coupés (Ids)',\n",
       " 'Sols coupants (u)',\n",
       " 'Sols coupants (Ids)',\n",
       " 'Sol au-dessus',\n",
       " 'Sol en-dessous',\n",
       " 'Fenêtres',\n",
       " 'Portes',\n",
       " 'Ouvertures',\n",
       " 'Murs imbriqués',\n",
       " 'Mur multicouche',\n",
       " 'Mur empilé',\n",
       " 'Profil modifié',\n",
       " 'Image',\n",
       " 'Catégorie',\n",
       " 'Section',\n",
       " \"Type prédéfini d'IFC\",\n",
       " 'Exporter au format IFC sous',\n",
       " 'Exporter au format IFC',\n",
       " 'IfcGUID',\n",
       " 'A une association',\n",
       " \"Enrobage d'armature - Autres faces\",\n",
       " \"Enrobage d'armature - Face intérieure\",\n",
       " \"Enrobage d'armature - Face extérieure\",\n",
       " 'Variantes',\n",
       " 'Extension inférieure',\n",
       " 'Extension supérieure',\n",
       " 'Volume',\n",
       " 'Surface',\n",
       " 'Phase de démolition',\n",
       " 'Phase de création',\n",
       " 'Commentaires',\n",
       " 'Longueur',\n",
       " 'Famille et type',\n",
       " 'Famille',\n",
       " 'Type',\n",
       " 'Nom de la famille',\n",
       " 'Nom du type',\n",
       " 'ID du type',\n",
       " 'Lié au volume',\n",
       " 'Structure',\n",
       " 'Identifiant',\n",
       " 'Ligne de justification',\n",
       " 'Utilisation structurelle',\n",
       " 'Partie inférieure attachée',\n",
       " 'Partie supérieure attachée',\n",
       " 'Décalage supérieur',\n",
       " 'Décalage inférieur',\n",
       " 'Contrainte inférieure',\n",
       " 'Hauteur non contrainte',\n",
       " 'Contrainte supérieure',\n",
       " 'Limite de pièce',\n",
       " 'Visible dans les nomenclatures',\n",
       " '*200EC_NomObjet',\n",
       " '*202EC_Largeur',\n",
       " '*203EC_Hauteur',\n",
       " '*204EC_Longueur',\n",
       " '*207EC_SurfaceVideDeduit',\n",
       " '*208EC_SurfaceTotaleOuvertures',\n",
       " '*210EC_SurfaceVidePourPlein',\n",
       " '*213EC_SurfaceCoffrage',\n",
       " '*215EC_Surface projetee',\n",
       " '*216EC_VolumeTotal',\n",
       " '*217EC_VolumePrefa',\n",
       " '*218EC_VolumeACouler',\n",
       " '*220EC_Hôte',\n",
       " '*221EC_Inclusion',\n",
       " '*222EC_Quantite',\n",
       " '001EC_Grue',\n",
       " '002EC_Batiment',\n",
       " '003EC_Zone',\n",
       " '004EC_Nom Etage',\n",
       " '005EC_Code Etage',\n",
       " '021EC_Specificite',\n",
       " '022EC_Classe Beton',\n",
       " '023EC_Materiau',\n",
       " '031EC_RatioHA_ml',\n",
       " '032EC_RatioTS_ml',\n",
       " '033EC_RatioHA_m2',\n",
       " '034EC_RatioTS_m2',\n",
       " '035EC_RatioHA_m3',\n",
       " '036EC_RatioTS_m3',\n",
       " '037EC_EpaisseurBetonPrefa',\n",
       " '*038EC_MasseHA',\n",
       " '*039EC_MasseTS',\n",
       " '041EC_Option Logetex 1',\n",
       " '042EC_Option Logetex 2',\n",
       " '043EC_Option Logetex 3',\n",
       " '051EC_Date Realisation',\n",
       " '054EC_Jour Coulage',\n",
       " '055EC_Jour Coulage Cumule',\n",
       " '081EC_Clef Generique',\n",
       " '082EC_Clef Logetex',\n",
       " '083EC_Clef Carbone',\n",
       " '084EC_Clef Planification',\n",
       " '085EC_Clef Grue',\n",
       " '201EC_VoileInterieur',\n",
       " 'IdGtcParameter',\n",
       " 'IdGtcParameterCreationTime',\n",
       " '*223EC_HauteurCoffrage',\n",
       " '024EC_Finition GO',\n",
       " '044EC_RatioHA_U',\n",
       " '045EC_RatioTS_U',\n",
       " '056EC_Heure Grue',\n",
       " '086EC_Clef ModeConstructif',\n",
       " '087EC_Clef AB',\n",
       " '088EC_Clef BMO',\n",
       " 'Image du type',\n",
       " \"Note d'identification\",\n",
       " \"Type: Type prédéfini d'IFC\",\n",
       " 'Exporter le type au format IFC sous',\n",
       " 'Exporter le type au format IFC',\n",
       " 'Type IfcGUID',\n",
       " 'Modèle',\n",
       " 'Fabricant',\n",
       " 'Commentaires du type',\n",
       " 'URL',\n",
       " 'Description',\n",
       " 'Matériau structurel',\n",
       " 'Rugosité',\n",
       " \"Coefficient d'absorbance\",\n",
       " 'Masse thermique',\n",
       " 'Résistance thermique (R)',\n",
       " 'Coefficient de transfert thermique (U)',\n",
       " \"Description de l'assemblage\",\n",
       " \"Code d'assemblage\",\n",
       " 'Retournement aux insertions',\n",
       " 'Retournement aux extrémités',\n",
       " 'Couleur vue détail faible',\n",
       " 'Motif vue détail faible',\n",
       " 'Marque de type',\n",
       " \"Protection contre l'incendie\",\n",
       " 'Coût',\n",
       " 'Fonction',\n",
       " 'Largeur',\n",
       " 'Composition',\n",
       " 'Niveau',\n",
       " 'Matériau biosourcé',\n",
       " 'IFCExportAs',\n",
       " 'EIF_STR - Impact',\n",
       " 'EC_Type de Mur',\n",
       " 'ID MONTAGE',\n",
       " 'Désignation système',\n",
       " 'Réf DT',\n",
       " 'Nature_Ouvrage',\n",
       " 'Batiment',\n",
       " 'Mur armé',\n",
       " 'Affichage poteau',\n",
       " 'NIVEAU_STRUCTURE',\n",
       " 'SOFiSTiK_EdgeZones',\n",
       " 'ASPC_PLANCHER HAUT',\n",
       " 'Porteur',\n",
       " 'Walls RDC Beton',\n",
       " 'Walls RDC Maconerie',\n",
       " 'Walls R+1 Beton',\n",
       " 'Walls R+1 Maconerie',\n",
       " 'Walls R+2 Beton',\n",
       " 'Walls R+2 Maconerie',\n",
       " 'Walls R+3 Beton',\n",
       " 'Walls R+3 Maconerie',\n",
       " 'Walls Terrasse',\n",
       " 'Walls R-1 Beton',\n",
       " 'Walls R-1 Maconerie',\n",
       " 'IfcExportAs',\n",
       " 'A-Code',\n",
       " 'Materiau',\n",
       " \"Code de l'ouvrage\",\n",
       " 'VCF_Codification_MCMT',\n",
       " 'VCF_Codification',\n",
       " 'A-Degré Feu',\n",
       " 'A-Remplissage demolition',\n",
       " 'IfcDescription',\n",
       " 'Modifié par',\n",
       " 'Sous-projet',\n",
       " 'A_Bâtiment',\n",
       " 'A_Classement au feu',\n",
       " 'A_Acoustique',\n",
       " 'A_Hors marché',\n",
       " 'Légende détails',\n",
       " 'T - Teinte',\n",
       " 'T - Finition',\n",
       " 'EC.R Niveau',\n",
       " 'EC.R Ouvrage',\n",
       " 'EC.R Suffixe',\n",
       " 'EC.R Zone',\n",
       " 'EC.R Couleur',\n",
       " 'EC.R Voile about G.type',\n",
       " 'Activer le modèle analytique',\n",
       " 'EC.R Voile about G.id',\n",
       " 'EC.R Hauteur',\n",
       " 'Nombre mannequins',\n",
       " 'EC.R Coffrage Hauteur',\n",
       " 'EC.R Longueur',\n",
       " 'EC.R Voile about D.id',\n",
       " 'EC.R Poids',\n",
       " 'EC.R Voile about D.type',\n",
       " 'EC.R Numero',\n",
       " 'EC.R Coffrage surface',\n",
       " 'EC.R Epaisseur',\n",
       " 'EC.R Ouvrage (T)',\n",
       " 'EC.R Coffrage faces II',\n",
       " 'EC.R Suffixe (T)',\n",
       " 'EC.R Coffrage faces I',\n",
       " 'Marque centrale visible',\n",
       " 'Extensions.Buffer3',\n",
       " 'Etage',\n",
       " 'Extensions.Buffer7',\n",
       " 'Extensions.Group',\n",
       " 'Extensions.Extensions',\n",
       " 'Extensions.Buffer5',\n",
       " 'Extensions.Buffer1',\n",
       " 'Mode constructif',\n",
       " 'Extensions.Buffer9',\n",
       " 'Extensions.Buffer4',\n",
       " 'Extensions.Position',\n",
       " 'Extensions.Buffer6',\n",
       " 'Extensions.Parameters',\n",
       " 'Extensions.ViewId',\n",
       " 'Grue / Zone',\n",
       " 'Extensions.Buffer',\n",
       " 'Bâtiment',\n",
       " 'Extensions.ID',\n",
       " 'Extensions.Buffer2',\n",
       " 'Extensions.Buffer8',\n",
       " 'Extensions.Tag',\n",
       " 'EC_MET_Achat prémurs',\n",
       " 'EC_MET_Ep. peaux prémurs',\n",
       " 'EC_MET_SMH',\n",
       " 'EC_MET_Aciers TS',\n",
       " 'EC_MET_Achat préfa',\n",
       " 'EC_MET_Aciers HA cf',\n",
       " 'EC_MET_Prix béton',\n",
       " 'EC_MET_Aciers HA cfa',\n",
       " 'TPFI_Etage',\n",
       " 'EIFF_METH_Jour de Pose',\n",
       " 'EIFF_METH_Jour de Rotation',\n",
       " 'EIFF_METH_Jour Etaiement',\n",
       " 'EIFF_METH_Commentaires',\n",
       " 'EIFF_METH_Jour de Ferraillage',\n",
       " 'EIFF_METH_Jour de Coulage',\n",
       " 'EIFF_Mode Constructif',\n",
       " 'EIFF_METH_Jour de Coffrage',\n",
       " 'GOE-Etage',\n",
       " 'GOE-Résistance Feu',\n",
       " 'GOE-Utilisation',\n",
       " 'Carastéristiques coupe-feu',\n",
       " 'GOE-Résistance Acoustique (Rw)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_concat.keys().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34acc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13508, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_list = [\n",
    "    \"011EC_Lot\",\n",
    "    \"012EC_Ouvrage\",\n",
    "    \"013EC_Localisation\",\n",
    "    \"014EC_Mode Constructif\",\n",
    "    \"Epaisseur\",\n",
    "    \"Sols en intersection\",\n",
    "    \"Sols coupés (u)\",\n",
    "    \"Sols coupants (u)\",\n",
    "    \"Sol au-dessus\",\n",
    "    \"Sol en-dessous\",\n",
    "    \"Fenêtres\",\n",
    "    \"Portes\",\n",
    "    \"Ouvertures\",\n",
    "    #\"Murs imbriqués\",\n",
    "    \"Mur multicouche\",\n",
    "    \"Profil modifié\",\n",
    "    #\"Extension inférieure\",\n",
    "    #\"Extension supérieure\",\n",
    "    \"Partie inférieure attachée\",\n",
    "    \"Partie supérieure attachée\",\n",
    "    \"Décalage supérieur\",\n",
    "    \"Décalage inférieur\",\n",
    "    \"Matériau structurel\",\n",
    "    \"Famille et type\"\n",
    "]\n",
    "\n",
    "targets = [\n",
    "    \"011ec_lot\",\n",
    "    \"012ec_ouvrage\",\n",
    "    \"013ec_localisation\",\n",
    "    \"014ec_mode_constructif\"\n",
    "]\n",
    "\n",
    "df_clean = dfs_concat[selected_features_list].dropna(axis=0, how='any')\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a6e2acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13508, 17), (13508, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoring '011EC_Lot' for now / all GO\n",
    "X = df_clean.drop(columns = ['012EC_Ouvrage','013EC_Localisation','014EC_Mode Constructif','011EC_Lot'])\n",
    "y = df_clean[['011EC_Lot']]#,'013EC_Localisation','014EC_Mode Constructif', '012EC_Ouvrage','011EC_Lot']]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ccddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the uniques for Epaisseur: 29\n",
      "the uniques for Sols en intersection: 7\n",
      "the uniques for Sols coupés (u): 2\n",
      "the uniques for Sols coupants (u): 11\n",
      "the uniques for Sol au-dessus: 2\n",
      "the uniques for Sol en-dessous: 2\n",
      "the uniques for Fenêtres: 13\n",
      "the uniques for Portes: 11\n",
      "the uniques for Ouvertures: 3\n",
      "the uniques for Mur multicouche: 2\n",
      "the uniques for Profil modifié: 2\n",
      "the uniques for Partie inférieure attachée: 2\n",
      "the uniques for Partie supérieure attachée: 2\n",
      "the uniques for Décalage supérieur: 532\n",
      "the uniques for Décalage inférieur: 343\n",
      "the uniques for Matériau structurel: 25\n",
      "the uniques for Famille et type: 143\n"
     ]
    }
   ],
   "source": [
    "for feat in X.columns:\n",
    "    print(f'the uniques for {feat}: {len(X[feat].unique())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547e2fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the uniques for Epaisseur: 29 || They are: \n",
      " [0.2  0.3  0.16 0.18 0.25 0.15 0.4  0.35 0.47 0.67 0.17 1.01 0.61 1.28\n",
      " 0.88 1.51 0.21 0.33 0.1  0.06 0.01 0.22 0.12 0.53 0.34 0.28 0.24 0.26\n",
      " 0.5 ]\n",
      "the uniques for Sols en intersection: 7 || They are: \n",
      " [0 1 2 3 4 9 8]\n",
      "the uniques for Sols coupés (u): 2 || They are: \n",
      " [0 1]\n",
      "the uniques for Sols coupants (u): 11 || They are: \n",
      " [ 3  1  2  4  5  6  7  0  8 10  9]\n",
      "the uniques for Sol au-dessus: 2 || They are: \n",
      " [ True False]\n",
      "the uniques for Sol en-dessous: 2 || They are: \n",
      " [ True False]\n",
      "the uniques for Fenêtres: 13 || They are: \n",
      " [ 0  1 15 13  2  3  4  8  5 18  6 10  7]\n",
      "the uniques for Portes: 11 || They are: \n",
      " [ 0  1  2  9  8  3  4  7  6  5 24]\n",
      "the uniques for Ouvertures: 3 || They are: \n",
      " [0 1 2]\n",
      "the uniques for Mur multicouche: 2 || They are: \n",
      " [False  True]\n",
      "the uniques for Profil modifié: 2 || They are: \n",
      " [ True False]\n",
      "the uniques for Partie inférieure attachée: 2 || They are: \n",
      " [0 1]\n",
      "the uniques for Partie supérieure attachée: 2 || They are: \n",
      " [0 1]\n",
      "the uniques for Décalage supérieur: 532 || They are: \n",
      " [ 0.00000000e+00  4.36973665e-01 -1.50000000e-01 -2.70000000e-01\n",
      " -3.00000000e-01 -7.00000000e-02 -7.00000000e-02 -7.00000000e-02\n",
      " -4.00000000e-01  2.57000000e+00  1.14400000e+00  3.06800000e+00\n",
      "  2.35200000e+00  1.80859655e+00  7.58800000e-01  7.58546798e-01\n",
      "  1.03400000e-01  2.63000000e-01  3.20024352e+00  7.56000000e-01\n",
      "  1.69165831e-01  1.55199997e+00  2.05800000e+00 -6.00000000e-03\n",
      "  1.00000000e+00  3.70000000e-01  3.70000000e-01  4.50000000e-01\n",
      " -5.90000000e+00 -8.70000000e-01 -2.30000000e-01  3.00000000e-16\n",
      "  2.12841458e-01 -2.50000000e-01 -2.00000000e-02 -2.00000000e-01\n",
      " -7.00000000e-01 -5.00000000e-01 -1.26000000e+00 -2.00000000e-01\n",
      " -3.07000000e+00 -3.27000000e+00 -3.27000000e+00 -2.67000000e+00\n",
      " -2.09000000e+00 -1.69000000e+00 -1.88000000e+00 -2.55000000e+00\n",
      " -1.25000000e+00 -4.04000000e+00 -2.80000000e+00 -3.69000000e+00\n",
      " -3.49000000e+00 -8.30000000e-01  1.00000000e-02  3.00000000e-01\n",
      " -4.70000000e-01 -4.70000000e-01 -1.30000000e-01 -5.70000000e-01\n",
      " -5.70000000e-01  1.50000000e-01 -6.20000000e-01  2.85000000e-01\n",
      "  4.35000000e-01 -1.50000000e-02  6.00000000e-01 -2.40033955e-01\n",
      " -2.70000000e-01 -2.10000000e-01 -1.53000000e+00 -1.50669922e+00\n",
      " -1.50670000e+00 -1.49640531e+00 -5.00000000e-01 -6.20000000e-01\n",
      " -1.03000000e+00  2.00000000e-01  7.00000000e-02 -2.00000000e-02\n",
      " -3.20000000e-01 -3.20000000e-01 -4.35000000e-01 -1.85000000e-01\n",
      "  1.35000000e-01 -4.70000000e-01  2.50000000e+00  3.16098611e+00\n",
      "  3.16100000e+00  2.03000044e-01  6.20000000e-01  5.00000000e-01\n",
      "  3.80000000e-01  6.40000000e-15 -1.38126339e-01 -7.00000000e-02\n",
      " -2.10000000e-01 -2.70000000e-01 -7.00000000e-02 -7.00000000e-02\n",
      " -7.00000000e-02 -7.00000000e-02 -3.00000000e-01 -7.00000000e-02\n",
      " -7.00000000e-02 -7.00000000e-02  1.23000000e+00 -7.00000000e-02\n",
      " -1.40000000e-01 -1.00000000e-15 -1.44740632e-01 -3.75963394e-01\n",
      " -2.70000000e-01 -7.00000000e-02 -2.70000000e-01 -3.69711370e-01\n",
      " -1.44740632e-01 -1.44740632e-01 -9.21613286e-01 -2.70000000e-01\n",
      " -9.00000000e-01 -3.75456900e-01 -1.44740632e-01  6.60458936e-01\n",
      " -9.24768143e-01 -2.70000000e-01 -7.00000000e-02 -7.00000000e-02\n",
      " -7.00000000e-02 -7.00000000e-02 -3.00000000e-01 -7.00000000e-02\n",
      " -7.00000000e-02 -7.00000000e-02 -2.70000000e-01 -7.50000000e-01\n",
      " -3.80000000e-01 -4.50000000e-01 -6.80000000e-01  1.10000000e-01\n",
      " -7.50000000e-01 -2.20000000e-01  1.00000000e+00 -2.70000000e-01\n",
      " -2.73105787e-01 -8.00000000e-02  2.80000000e+00  5.00000000e-01\n",
      "  5.80000000e-01  3.60000000e-14 -7.00000000e-01 -2.70000000e-01\n",
      " -3.70000000e-01  5.00000000e-01  5.00000000e-01  4.76000000e-01\n",
      " -2.00000000e-01 -4.80000000e-01 -2.70000000e-01  3.00000000e-01\n",
      " -4.20000000e-01  1.40000000e-15 -2.90000000e-01  1.30000000e-01\n",
      "  1.18570855e-01  8.00000000e-02  4.80001391e-01  4.80000000e-01\n",
      "  4.80000000e-01 -5.25813908e-01  1.47428685e+00  1.37378045e+00\n",
      "  4.03759361e-01  4.37162675e-01  1.08255150e+00 -1.35120000e+00\n",
      "  2.08000000e+00 -1.08000000e-14 -2.00000000e-01 -1.05000000e+00\n",
      " -8.30000000e-01 -1.07000000e+00 -8.70000000e-01 -1.09000000e+00\n",
      " -7.00000000e-02  1.89000000e+00 -3.81000000e+00 -3.78000000e+00\n",
      " -1.40000000e-01  1.60000000e-01  7.00000000e-02  1.89000000e+00\n",
      " -3.77542534e+00 -4.01000000e+00 -3.98000000e+00  1.86000000e+00\n",
      "  1.89457466e+00  1.86000000e+00  3.96297233e-02 -2.20000000e-01\n",
      "  4.00000000e-02 -9.90000000e-01  6.00000000e-02 -1.90000000e-01\n",
      "  2.30243691e-01 -3.00000000e-02 -6.00000000e-02  1.60000000e-01\n",
      " -1.40000000e-01 -8.30000000e-01 -4.00000000e-02 -1.60000000e-01\n",
      " -3.00000000e-01 -3.46000000e-14 -9.90000000e-01 -6.10000000e-01\n",
      "  6.17579276e-02  1.00000000e-02 -3.60000000e-01 -9.20000000e-01\n",
      " -2.20000000e-01 -1.22000000e+00 -5.90000000e-01 -1.12000000e+00\n",
      " -8.10000000e-01 -3.90000000e-01 -1.62000000e+00 -9.90000000e-01\n",
      " -2.00000000e-01 -1.19000000e+00 -2.50000000e-01  1.60000000e+00\n",
      " -9.97440926e-02 -5.00001692e-02 -5.00000000e-02 -6.00000000e-01\n",
      " -2.50000000e-01  8.80000000e-01  2.60000000e-01 -6.50000000e-01\n",
      " -1.03430000e+00 -2.20000000e-01 -9.87424754e-01 -7.20000000e-01\n",
      " -1.12000000e+00 -1.00000000e+00 -1.03000000e+00 -2.40000000e-01\n",
      " -6.90000000e-01  2.20000000e-01 -1.05000000e+00 -7.50000000e-01\n",
      "  1.70000000e-14 -9.00000000e-01  1.05000000e+00 -1.52000000e-14\n",
      "  8.50000000e-01  7.50000000e-01  4.00000000e-02 -9.60000000e-01\n",
      "  1.59000000e+00 -9.40000000e-01 -9.40000000e-01 -1.20000000e-01\n",
      " -1.07000000e+00 -4.30000000e-01 -3.20000000e-01  6.80000000e-01\n",
      " -4.90000000e-01 -1.30000000e+00 -1.50000000e+00 -1.02000000e+00\n",
      " -3.20000000e-01 -3.70000000e-01 -1.60000000e-01 -2.00000000e+00\n",
      " -9.00000000e-02  1.02000000e+00 -4.80000000e-01 -1.15000000e+00\n",
      " -3.50000000e-01 -8.50000000e-01  1.12000000e+00 -3.40000000e-01\n",
      " -6.50000000e-01 -2.80000000e-01 -8.30000000e-01 -5.00000000e-02\n",
      " -1.70000000e-01 -2.60000000e-01 -8.10000000e-01 -8.20000000e-01\n",
      " -7.90000000e-01 -3.90000000e-01 -5.00000000e-02 -3.50000000e+00\n",
      " -3.02200000e+00 -1.09000000e+00 -2.05000000e+00 -8.00000000e-01\n",
      " -8.80000000e-01 -2.30000000e-01 -2.85237320e-01 -1.84697149e-01\n",
      "  3.50000000e-01  2.00000000e-02 -1.19800000e-13  4.50000000e-15\n",
      " -2.20000000e-01 -8.52000000e-14 -2.20000000e-01  9.05700000e-01\n",
      "  9.05700000e-01  1.00000000e-02 -2.00000000e-02  2.57000000e+00\n",
      " -2.00000000e-02  2.00000000e-02 -6.60000000e-01 -3.90000000e-01\n",
      " -2.10000000e-01 -1.02700000e-13 -2.10000000e-01 -1.22000000e-13\n",
      " -2.20000000e-01  2.00000000e-02 -2.20000000e-01 -4.14300000e-01\n",
      " -4.40000000e-01 -4.40000000e-01 -4.40000000e-01 -1.20000000e-01\n",
      " -3.30000000e-01 -3.00000000e-01 -2.10000000e-01  9.20000000e-01\n",
      "  9.00000000e-01  9.00000000e-01  9.20000000e-01  5.54400000e-13\n",
      " -1.20000000e+00  1.00000000e-02  8.31600000e-13  7.62300000e-13\n",
      " -1.40000000e-01 -6.40000000e-01 -3.90000000e-01 -6.00000000e-02\n",
      " -2.20000000e-01 -2.20000000e-01 -2.20000000e-01 -2.80000000e-01\n",
      " -2.30000000e-01 -1.22000000e+00  1.00000000e-01  1.00000000e-01\n",
      " -8.00000000e-01  1.00000000e-01  1.00000000e-01  5.00000000e-02\n",
      "  1.80000000e+00  1.60000000e+00  8.00000000e-01  3.69809454e+00\n",
      " -3.03000000e+00 -2.10000000e+00 -1.80000000e+00 -3.02775462e+00\n",
      " -1.70000000e+00  2.00000000e-16 -1.00000000e+00 -7.04772923e-01\n",
      " -8.00000000e-01 -3.84764276e-01 -8.04317542e-01 -2.50000000e+00\n",
      "  9.00000000e-16  8.00000000e-02 -2.00000000e-16 -1.20000000e-01\n",
      "  8.00000000e-02  8.00000000e-02 -4.00000000e-01 -2.50000000e-01\n",
      " -2.52893549e-01 -2.64767220e-01 -8.50000000e-01 -8.50000000e-01\n",
      " -1.10000000e-01 -7.00000000e-01  1.34962523e+00 -1.88160179e-01\n",
      " -5.00000000e-02 -5.00000000e-02 -5.00000000e-02  1.75000000e+00\n",
      "  1.15000000e+00  3.25000000e+00  3.20000000e-01 -1.20000000e-15\n",
      "  7.00000000e-01  3.86470000e+00  1.33000000e+00 -8.50000000e-01\n",
      "  3.50000000e-15  8.00000000e-02  8.00000000e-02  8.00000000e-02\n",
      "  8.00000000e-02  8.00000000e-02  8.00000000e-02  8.00000000e-02\n",
      "  8.00000000e-02 -1.20000000e-01 -1.20000000e-01 -1.50000000e-01\n",
      "  6.10000000e-01  2.02629659e-01  3.70322514e-01 -2.80000000e-01\n",
      "  2.10000000e-01 -3.99716181e-01 -2.00000000e-01 -7.50000000e-15\n",
      " -1.10000000e+00 -7.00000000e-01 -7.00000000e-02 -2.70000000e-01\n",
      " -8.00000000e-01 -7.88428109e-01 -5.00000000e-02 -7.00000000e-01\n",
      "  2.50000000e-01  1.30000000e-01  3.30000000e-01  2.41961893e-01\n",
      " -7.00000000e-02  2.39454612e-01 -2.61000000e+00 -2.90000000e-01\n",
      " -2.90325242e-01  3.20748189e-01 -7.00000000e-01 -4.00000000e-01\n",
      " -6.20000000e-01 -5.00000000e-01  2.65000000e+00 -2.95410558e-01\n",
      "  2.41429740e-01  2.41428571e-01 -2.60000000e-01 -1.20000000e-01\n",
      " -7.88535796e-03 -1.05453880e-02  8.00000000e-02  3.19000000e-01\n",
      " -2.00000000e-01  3.30000000e-01 -3.70000000e-01 -2.70000000e-01\n",
      " -4.50456045e-01 -3.25792179e-01 -1.90566248e+00 -2.50085434e-01\n",
      " -3.20000000e+00 -2.50000000e-01 -1.24566327e+00 -6.00000000e-01\n",
      " -1.91405422e+00 -1.50000000e-01 -1.50000000e-01 -1.50000000e-01\n",
      " -1.50000000e-01 -3.20000000e-01 -1.37000000e+00 -7.20000000e-01\n",
      "  3.07000000e+00 -4.20000000e-01 -1.50000000e-01 -8.32545346e-01\n",
      " -2.60000000e-01 -1.10000000e-01 -1.20000000e-01 -3.70000000e-01\n",
      " -2.50000000e-01 -2.40000000e+00 -4.20000000e-01  1.75000000e+00\n",
      "  4.60000000e-01  4.60000000e-01 -1.19000000e-01  6.10000000e-01\n",
      " -6.30000000e-01 -6.30000000e-01 -1.80000000e-01 -1.80000000e-01\n",
      " -4.10000000e-01 -8.00000000e-02 -3.90000000e-01 -3.50000000e-01\n",
      "  1.80425602e-01  1.80000000e-01  1.80000000e-01 -1.50000000e-01\n",
      " -1.50000000e-01 -1.50000000e-01 -8.00000000e-02  4.61000000e-01\n",
      "  5.60000000e-01 -2.00000000e-02 -6.50000000e-02 -6.50000000e-02\n",
      " -8.00000000e-02  1.29500000e+00 -4.00000000e-01  1.50000000e+00\n",
      " -1.52352185e-01  1.32000000e+00  2.02000000e+00 -3.50000000e-01\n",
      " -3.20000000e-01 -4.00000000e-01 -9.83079956e-01  1.25400000e+00\n",
      " -4.10000000e-01  6.10000000e-01 -4.10000000e-01 -6.50000000e-02\n",
      "  2.60000000e+00  6.70000000e-01 -1.12000000e+00 -9.00000000e-01]\n",
      "the uniques for Décalage inférieur: 343 || They are: \n",
      " [ 0.00000000e+00 -4.50000000e-01 -5.00000000e-01 -7.50000000e-01\n",
      " -7.00000000e-01 -4.00000000e-01 -9.50000000e-01 -7.00000000e-02\n",
      " -1.50000000e+00 -7.00000000e-02 -3.00000000e-01  1.77000000e+00\n",
      " -1.99338674e+00  2.75000000e+00 -2.00000000e-02 -2.00000000e-02\n",
      " -1.30000000e-01  9.70000000e-01 -2.00000000e-01 -1.40000000e+00\n",
      " -2.00000000e-02 -6.00000000e-01 -6.00000000e-01  1.30000000e-01\n",
      " -8.00000000e-02 -1.20000000e-01  1.00000000e-02 -2.70000000e-01\n",
      " -2.70000000e-15  9.70000000e-01  9.72031202e-01 -5.70000000e-01\n",
      " -4.70000000e-01  2.65000000e+00  2.41500000e+00 -5.90000000e-01\n",
      " -3.20000000e-15 -4.05000000e-01 -8.30000000e-01 -8.00000000e-01\n",
      "  3.01500000e+00  2.80027078e+00  2.22500000e+00  2.25000000e+00\n",
      " -1.24141125e+00  2.64747465e+00 -3.50000000e-01 -2.20000000e-01\n",
      "  3.80000000e-01 -1.10000000e+00 -1.15000000e+00  5.50000000e-01\n",
      "  1.35000000e+00  2.05000000e+00  5.50000000e-01 -1.50000000e-01\n",
      " -3.50000000e-01 -1.50000000e-01 -1.50000000e-01 -1.37265822e+00\n",
      " -7.00000000e-02 -7.00000000e-02 -7.00000000e-02 -7.00000000e-02\n",
      " -7.00000000e-02 -7.00000000e-02 -7.00000000e-02 -1.50000000e-01\n",
      " -7.00000000e-02 -7.00000000e-02 -2.90000000e-01  1.10000000e-01\n",
      " -7.00000000e-02 -4.70535866e-01 -7.00000000e-02 -6.75689181e-02\n",
      " -1.00000000e-01 -7.00000000e-02 -7.00000000e-02  2.40000000e+00\n",
      " -7.01598207e-02 -1.15368529e-01 -7.00000000e-02 -7.00000000e-02\n",
      "  2.20000000e+00 -7.40196170e-02 -7.00000000e-02 -7.00000000e-02\n",
      " -7.59791682e-02 -7.00000000e-02 -1.06283474e-01 -6.90263232e-02\n",
      " -2.90000000e-01 -1.50000000e-01 -6.65166117e-02 -7.00000000e-02\n",
      "  2.50000000e+00 -1.57000000e+00 -4.90000000e-01 -1.20000000e-01\n",
      "  3.00000000e+00 -4.70191818e-01  2.70000000e+00 -7.00000000e-02\n",
      " -1.54843258e-01  3.00000000e-01  7.72000000e-13 -2.00000000e-01\n",
      "  7.83900000e-13  5.00000000e-01 -2.01738351e-01  4.00000000e-01\n",
      " -2.00379026e-01  1.00000000e-02 -2.00000000e-01 -2.00000000e-01\n",
      " -2.00000000e-01 -2.00000000e-02 -2.00000000e-02 -2.00000000e-02\n",
      " -2.00000000e-02 -2.00000000e-02 -6.90000000e-01 -5.30000000e-01\n",
      " -3.00000000e-02 -9.97440926e-02  2.20000000e-01  1.69347771e-07\n",
      " -1.00000000e-01 -4.20000000e-01  4.80001391e-01  1.14200000e-01\n",
      "  2.76418609e+00 -5.43257988e-01  1.00000000e-02 -2.50500002e-01\n",
      " -5.00000002e-01 -4.79000000e-01 -4.49043821e-01  1.00000000e-01\n",
      "  3.50956179e-01  7.00000000e-02  1.05000000e+00 -4.00000000e-02\n",
      "  1.05000000e+00  2.00000000e-02  1.05542534e+00 -1.09542534e+00\n",
      " -1.97871565e-02  1.89000000e+00  1.89457466e+00  1.89000000e+00\n",
      "  1.86000000e+00  4.94392672e-03 -1.08542534e+00 -9.39680429e-01\n",
      " -9.20000000e-01 -8.30000000e-01 -8.30000000e-01 -8.70000000e-01\n",
      " -9.30000000e-01  1.86000000e+00  1.60000000e-01  9.00000000e-02\n",
      "  1.60000000e-01  2.20000000e-01  2.00000000e-01 -3.00000000e-02\n",
      "  2.30000000e-01  2.30243691e-01  9.00000000e-02  1.59000000e-14\n",
      " -5.30000000e-01  3.96297233e-02  4.00000000e-02  6.17579276e-02\n",
      "  6.00000000e-02  2.20000000e-15 -8.20000000e-01 -1.99977819e-02\n",
      "  1.86000000e+00  1.20000000e-01 -6.90000000e-01  1.89000000e+00\n",
      "  4.80000000e-01  2.00000000e-02 -1.13000000e+00 -1.11000000e+00\n",
      "  6.00000000e-02  6.80000000e-01  6.80000000e-01 -2.80000000e-01\n",
      "  2.00000000e+00 -8.50000000e-01 -9.00000000e-02  1.02000000e+00\n",
      "  1.02000000e+00 -5.00000000e-02 -3.40000000e-01 -3.80000000e-01\n",
      " -4.40000000e-01 -9.00000000e-01 -2.00000000e-02 -1.68700000e-13\n",
      " -2.00000000e-02 -5.00000000e-02 -2.28300000e-13  2.90000000e-01\n",
      "  2.00000000e-02  2.00000000e-02 -1.19800000e-13 -8.52000000e-14\n",
      "  1.42000000e-14 -1.10000000e+00 -2.00000000e-02 -4.05700885e-02\n",
      "  2.30000000e-15 -1.03900000e-13 -1.22000000e-13  2.00000000e-02\n",
      " -2.30000000e-01 -3.00000000e-01 -2.10000000e-01 -2.10000000e-01\n",
      " -1.33000000e+00 -2.30000000e-01 -1.92000000e+00  5.54400000e-13\n",
      " -1.20000000e+00  7.62300000e-13 -2.70000000e-01 -1.40000000e-01\n",
      " -4.30000000e+00 -1.90000000e+00 -1.92000000e+00 -9.30000000e-01\n",
      " -1.22000000e+00 -1.22000000e+00 -1.40000000e-01 -4.80000000e-01\n",
      "  4.50000000e-01 -1.00000000e+00  2.00000000e-01 -7.90000000e-01\n",
      " -7.90000000e-01  7.00000000e-02  5.30000000e+01  5.21200000e+01\n",
      " -5.00000000e-02 -3.20000000e-01 -1.00000000e-16 -1.75000000e+00\n",
      " -3.60000000e-01 -1.16000000e+00  3.30000000e-01  1.30000000e-15\n",
      " -3.20000000e-01  2.41428571e-01  2.41429740e-01 -6.00000000e-02\n",
      " -1.55000000e+00  1.86000000e-14  8.00000000e-02 -4.10000000e-01\n",
      " -5.10000000e-01  4.00000000e-01 -2.00000000e-02  3.20000000e-01\n",
      " -4.00000000e-01 -5.00000000e-02 -8.10000000e-01 -1.50000000e-01\n",
      " -4.50000000e-01 -1.00000000e-15  8.00000000e-02  8.00000000e-02\n",
      " -1.20000000e-01  8.00000000e-02  8.00000000e-02 -1.12000000e+00\n",
      "  7.50000000e-01 -7.50000000e-01 -1.05000000e+00  8.00000000e-02\n",
      " -8.03810701e-03 -1.05453880e-02 -1.20000000e-01 -7.88535796e-03\n",
      "  1.44000000e+00 -8.10000000e-01 -2.50000000e-01 -7.00000000e-02\n",
      " -4.10000000e-01 -4.10000000e-01 -4.10000000e-01 -4.10000000e-01\n",
      "  1.65000000e+00 -4.10000000e-01  1.24000000e+00  4.50997229e+00\n",
      " -6.00000000e-02  8.00000000e-16  1.65000000e+00  1.90000000e-01\n",
      " -8.90000000e-01 -1.99000000e+00 -1.50000000e-01 -4.10000000e-01\n",
      " -3.90000000e-01 -5.80000000e-01 -3.20000000e-01 -1.50000000e-01\n",
      " -4.00000000e-01 -4.80000000e-01 -3.20000000e-01 -1.53000000e+00\n",
      " -3.50000000e-01 -4.00000000e-01 -8.00000000e-02 -6.00000000e-01\n",
      " -6.70000000e-01 -1.34000000e+00 -4.10000000e-01 -1.50000000e-01\n",
      " -4.10000000e-01 -1.19000000e+00 -8.80000000e-01 -8.80000000e-01\n",
      " -5.50000000e-01 -3.50000000e-01 -1.54000000e+00 -4.10000000e-01\n",
      " -1.50000000e-01 -1.49000000e+00 -1.34000000e+00 -3.60000000e-01\n",
      "  1.29500000e+00  3.10266269e+00  4.70000000e-01 -6.30000000e-01\n",
      " -8.80000000e-01  2.60000000e+00  6.84328621e-01]\n",
      "the uniques for Matériau structurel: 25 || They are: \n",
      " ['ECSA - Béton Voiles' 'EC - Béton' '<Par catégorie>'\n",
      " 'Maçonnerie - Voile BA' 'Blocs béton manufacturés' 'C25/30' 'Maçonnerie'\n",
      " 'BRIQUES' 'BÉTON' 'BRIQUES RAL 1013' 'EIF_STR - BETON'\n",
      " '.EC.R Béton TOUS chantier' 'Verre' 'C25/30 - béton standard'\n",
      " 'C25/30 - peaux extérieures prémurs' 'Maçonnerie - Parpaing creux'\n",
      " 'C25/30 - éléments préfa' 'Maçonnerie - Parpaing plein' 'TPFI_BA'\n",
      " 'TPFI_BOIS' 'GOE-Béton Coulé sur place-1ere PHASE'\n",
      " 'GOE-Béton Coulé sur Place' 'GOE-Parpaings Creux'\n",
      " 'GOE-Béton Coulé sur Place-VNP' 'GOE-Parpaings Pleins']\n",
      "the uniques for Famille et type: 143 || They are: \n",
      " ['Mur de base: Voile BA 20' 'Mur de base: Voile BA 30'\n",
      " 'Mur de base: Voile BA 16' 'Mur de base: EIF_VOILE_INT 16'\n",
      " 'Mur de base: EIF_VOILE_INT_20' 'Mur de base: EIF_VOILE_INT 18'\n",
      " 'Mur de base: EIF-VOILE-EXT-PARPAING 20' 'Mur de base: EIF_VOILE_EXT_20'\n",
      " 'Mur de base: ECA-Voile BA 200 mm' 'Mur de base: ECA-Voile BA 180 mm'\n",
      " 'Mur de base: ECA-Voile BA 250 mm' 'Mur de base: ECA-Voile BA 300 mm'\n",
      " 'Mur de base: ECA-Int. Parpaing 150 mm'\n",
      " 'Mur de base: ECA-Int. Parpaing 200 mm'\n",
      " 'Mur de base: ECA-Voile BA 400 mm' 'Mur de base: Mur BA ép.25 C25/30'\n",
      " 'Mur de base: Mur BA ép.20 C25/30' 'Mur de base: Mur agglos ép.15cm'\n",
      " 'Mur de base: Mur BA ép.35 C25/30' 'Mur de base: Relevé BA ep50cm'\n",
      " 'Mur de base: Relevé BA ep67cm' 'Mur de base: Mur BA ép.17 C25/30'\n",
      " 'Mur de base: Relevé BA ep101cm' 'Mur de base: Mur BA ép.15 C25/30'\n",
      " 'Mur de base: Mur BA ép.30 C25/30' 'Mur de base: Mur BA ép.61 C25/30'\n",
      " 'Mur de base: Relevé BA ep128cm' 'Mur de base: Relevé BA ep88cm'\n",
      " 'Mur de base: Mur BA ép.18 C25/30' 'Mur de base: Mur agglos ép.20cm'\n",
      " 'Mur de base: Relevé BA ep151cm' 'Mur de base: ECRL_MUR_EP20cm'\n",
      " 'Mur de base: ECRL_MUR_EP18cm' 'Mur de base: BRIQUE 20'\n",
      " 'Mur de base: Béton 16' 'Mur de base: Béton 20'\n",
      " 'Mur de base: BRIQUE 20 + ENDUIT 1013' 'Mur de base: Béton 18'\n",
      " 'Mur de base: EIF_STR - Mur ep. 16' 'Mur de base: EIF_STR - PVe ep. 16'\n",
      " 'Mur de base: EIF_STR - Mur ep. 20'\n",
      " 'Mur de base: EIF_STR - Maçonnerie NP ep. 16'\n",
      " 'Mur de base: EIF_STR - Mur ep. 18' 'Mur de base: EIF_STR - PV ep. 20'\n",
      " 'Mur de base: EIF_STR - PV ep. 18' 'Mur de base: EIF_STR - PVe ep. 18'\n",
      " 'Mur de base: EIF_STR - PV ep. 16'\n",
      " 'Mur de base: EIF_STR - Maçonnerie NP ep. 18'\n",
      " 'Mur de base: EIF_STR_ Mur 16cm' 'Mur de base: EIF_STR_ Mur 20cm'\n",
      " 'Mur de base: EIF_STR_ Mur 30cm' 'Mur de base: EIF_STR_ Mur 35cm'\n",
      " 'Mur de base: EIF_STR_ Mur 25cm' 'Mur de base: EIF_STR_ Mur 21cm'\n",
      " 'Mur de base: EIF_STR_ Mur 33cm' 'Mur de base: EIF_STR_ Mur 20cm P01'\n",
      " 'Mur de base: EIF_STR_ Mur 18cm' 'Mur de base: EIF_STR_ Mur 10cm'\n",
      " 'Mur de base: EIF_STR_ Mur 6cm' 'Mur de base: EIF_STR_Vitrage balcon'\n",
      " 'Mur de base: EIF_STR_ Mur 22cm'\n",
      " 'Mur de base: EIF_STR_Voile non-porteur 20cm'\n",
      " 'Mur de base: EIF_STR_Voile non-porteur 16cm'\n",
      " 'Mur de base: EIF_STR_Voile non-porteur 18cm'\n",
      " 'Mur de base: EIF_STR_ Mur 12cm'\n",
      " 'Mur de base: EIF_STR_Voile non-porteur 25cm'\n",
      " 'Mur de base: EC_MET_GO_Voile BA 25cm'\n",
      " 'Mur de base: EC_MET_GO_Prémur 20cm'\n",
      " 'Mur de base: EC_MET_GO_Voile BA 20cm'\n",
      " 'Mur de base: EC_MET_GO_Parpaing 20 creux'\n",
      " 'Mur de base: EC_MET_GO_Voile BA 30cm'\n",
      " 'Mur de base: EC_MET_GO_Prémur 30cm' 'Mur de base: EC_MET_GO_Prémur 25cm'\n",
      " 'Mur de base: EC_MET_GO_Préfa BA 20cm'\n",
      " 'Mur de base: EC_MET_GO_Parpaing 20 plein'\n",
      " 'Mur de base: EC_MET_GO_Voile BA 53cm'\n",
      " 'Mur de base: TPFI-BETON ARME-Voile S.sol-25'\n",
      " 'Mur de base: TPFI-BETON ARME-Voile S.sol-20'\n",
      " 'Mur de base: TPFI-BETON ARME-voile s.sol 25'\n",
      " 'Mur de base: TPFI-BETON ARME-voile s.sol 30'\n",
      " 'Mur de base: TPFI-BETON ARME-V.Intérieur porteur-20'\n",
      " 'Mur de base: TPFI-BETON ARME-V.Intérieur Porteur-18'\n",
      " 'Mur de base: TPFI-BETON ARME-V.Extérieur Porteur-16'\n",
      " 'Mur de base: TPFI-BETON ARME-V.Intérieur Porteur-16'\n",
      " 'Mur de base: TPFI-FOB-34'\n",
      " 'Mur de base: TPFI-BETON ARME-Mur extérieur porteur-16'\n",
      " 'Mur de base: TPFI-BETON ARME-V.extérieur porteur-18'\n",
      " 'Mur de base: TPFI-BETON ARME-V.Extérieur porteur-20'\n",
      " 'Mur de base: TPFI-BETON ARME-V.Intérieur non Porteur-15'\n",
      " 'Mur de base: TPFI-BETON ARME-V.Intérieur non Porteur-16'\n",
      " 'Mur de base: TPFI-BETON ARME-Voile intérieur non porteur-20'\n",
      " 'Mur de base: TPFI-BETON ARME-Voile intérieur porteur-18'\n",
      " 'Mur de base: TPFI-BETON ARME-Voile intérieur porteur-20'\n",
      " 'Mur de base: TPFI-BETON ARME-mur intérieur porteur-20'\n",
      " 'Mur de base: TPFI-BETON ARME-mur intérieur porteur-25'\n",
      " 'Mur de base: TPFI-BETON ARME-mur intérieur non porteur-20'\n",
      " 'Mur de base: TPFI-BETON ARME-mur intérieur porteur-18'\n",
      " 'Mur de base: TPFI-BETON ARME-voile s.sol 20'\n",
      " 'Mur de base: TPFI-BETON ARME-Mur intérieur porteur-16'\n",
      " 'Mur de base: ECRL_MUR_EP35cm' 'Mur de base: ECRL_MUR_EP30cm'\n",
      " 'Mur de base: VPP 25cm' 'Mur de base: VPP 20cm'\n",
      " 'Mur de base: Voile Int ep 0.20' 'Mur de base: Voile Int ep 0.30'\n",
      " 'Mur de base: Voile Int ep 0.16' 'Mur de base: Voile Int ep 0.25'\n",
      " 'Mur de base: Voile ext ep 0.16' 'Mur de base: Voile ext ep 0.30'\n",
      " 'Mur de base: Voile ext ep 0.20' 'Mur de base: Voile Int ep 0.18'\n",
      " 'Mur de base: PoutreVoile - ep 0.20' 'Mur de base: Voile Int ep 0.22'\n",
      " 'Mur de base: Voile Int ep 0.15' 'Mur de base: Acrotère Courant (0.28ht)'\n",
      " 'Mur de base: Acrotère TTJardin (0.85ht)'\n",
      " 'Mur de base: Edicule Ascenseur 0.20' 'Mur de base: Relevé .12x.12 JD'\n",
      " 'Mur de base: Générique - 200 mm' 'Mur de base: GOE-VPP 30cm'\n",
      " 'Mur de base: GOE-Voile BA 30cm' 'Mur de base: GOE-Voile BA 20cm'\n",
      " 'Mur de base: GOE-Voile BA 25cm' 'Mur de base: GOE-Parpaing Creux 20cm'\n",
      " 'Mur de base: GOE-Voile BA 15cm' 'Mur de base: GOE-Voile BA 18cm'\n",
      " 'Mur de base: GOE-Voile BA 20cm VNP'\n",
      " 'Mur de base: GOE-Parpaing Plein 10cm'\n",
      " 'Mur de base: GOE-Voile BA 30cm VNP' 'Mur de base: GOE-Voile BA 28cm'\n",
      " 'Mur de base: GOE-Parpaing Creux 15cm'\n",
      " 'Mur de base: GOE-Parpaing Plein 15cm' 'Mur de base: GOE-Voile BA 40cm'\n",
      " 'Mur de base: GOE-Relevé 15cm ép' 'Mur de base: GOE-Facade 15cm ép'\n",
      " 'Mur de base: GOE-Relevé 20cm ép' 'Mur de base: GOE-Relevé 16cm ép'\n",
      " 'Mur de base: GOE-Relevé 25cm ép' 'Mur de base: GOE-Voile BA 16cm'\n",
      " 'Mur de base: GOE-Relevé 24cm ép' 'Mur de base: GOE-Facade 26cm ép'\n",
      " 'Mur de base: GOE-Voile BA 50cm' 'Mur de base: ECRL_MOB_EP15cm']\n"
     ]
    }
   ],
   "source": [
    "for feat in X.columns:\n",
    "    print(f'the uniques for {feat}: {len(X[feat].unique())} || They are: \\n {X[feat].unique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d93db061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boolean to 0/1 for\n",
    "bool_feats = ['Sol au-dessus', 'Sol en-dessous','Mur multicouche','Profil modifié']\n",
    "for feat in bool_feats:\n",
    "    X[feat] = X[feat].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da0ef6",
   "metadata": {},
   "source": [
    "# Scaling X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "542aa6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features to scale:\n",
    "feats_to_scale = ['Epaisseur','Décalage supérieur','Décalage inférieur']\n",
    "\n",
    "#minmax scaling X features\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#std_scaler = StandardScaler()\n",
    "\n",
    "for feat in feats_to_scale:\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    X[feat] = minmax_scaler.fit_transform(X[[feat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1de322",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "894b8722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
      "/tmp/ipykernel_161139/496863905.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "feats_to_encode = ['Matériau structurel', 'Famille et type']\n",
    "\n",
    "for feat in feats_to_encode:\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "    ohe.fit(X[[feat]])\n",
    "    X[ohe.get_feature_names_out()] = ohe.transform(X[[feat]])\n",
    "    X.drop(columns=[feat], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ae2df",
   "metadata": {},
   "source": [
    "# TARGET WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f8df6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>011EC_Lot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9653</th>\n",
       "      <td>GO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12386</th>\n",
       "      <td>GO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>GO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      011EC_Lot\n",
       "9653         GO\n",
       "12386        GO\n",
       "139          GO"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dc13dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>011EC_Lot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   011EC_Lot\n",
       "0          2\n",
       "1          2\n",
       "2          2\n",
       "3          2\n",
       "4          2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode all columns in y to numerical values\n",
    "y_encoded = y.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y_encoded[col] = le.fit_transform(y[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "y_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a9525",
   "metadata": {},
   "source": [
    "## DL MODELing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b62af3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e401cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9455, 183), (4053, 183), (9455, 1), (4053, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded,\n",
    "\t\t\t\t\t\t\t\t\t\t\ttest_size=0.3,\n",
    "\t\t\t\t\t\t\t\t\t\t\trandom_state=5)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ed76e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_len = len(y['011EC_Lot'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "820fd8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:58:07.740439: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-06 12:58:07.832544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-06-06 12:58:07.832556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-06-06 12:58:07.853138: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-06 12:58:08.443737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-06 12:58:08.443788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-06 12:58:08.443794: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input, layers, optimizers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce133e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(183,)))\n",
    "model.add(layers.Dense(1000, activation='relu'))\n",
    "model.add(layers.Dense(500, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(feat_len, activation='Softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45f2c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. COMPILATION\n",
    "adam_opt = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam_opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67d41099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1000)              184000    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 500)               500500    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 50)                25050     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709,703\n",
      "Trainable params: 709,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f02dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "414/414 [==============================] - 2s 3ms/step - loss: 0.0326 - accuracy: 0.9938 - val_loss: 0.0129 - val_accuracy: 0.9989\n",
      "Epoch 2/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.0026 - val_accuracy: 0.9989\n",
      "Epoch 3/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0158 - accuracy: 0.9986 - val_loss: 0.0124 - val_accuracy: 0.9989\n",
      "Epoch 4/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0025 - val_accuracy: 0.9989\n",
      "Epoch 5/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0066 - val_accuracy: 0.9989\n",
      "Epoch 6/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9989\n",
      "Epoch 7/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9989\n",
      "Epoch 8/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9989\n",
      "Epoch 9/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 10/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 11/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9989\n",
      "Epoch 12/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 13/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9989\n",
      "Epoch 14/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 15/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 16/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 17/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 18/80\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x749b542822c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = callbacks.EarlyStopping(patience=12, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=80,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9aadd782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d693f2e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'feat_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/BImpredict2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/BImpredict2/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/BImpredict2/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'feat_len'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m----> 3\u001b[0m y_test_cat \u001b[38;5;241m=\u001b[39m to_categorical(\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat_len\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#y_pred_ready = pd.DataFrame(np.argmax(y_pred, axis=1))\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/BImpredict2/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/BImpredict2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'feat_len'"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_test_cat = to_categorical(y_test['feat_len'], num_classes=3)\n",
    "\n",
    "#y_pred_ready = pd.DataFrame(np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48545368",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ready = pd.DataFrame(np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c490fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004017095547169447, 0.9980261325836182]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "665ec47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.86      0.46      0.60       105\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.47      0.89      0.62         9\n",
      "           4       0.87      0.74      0.80       283\n",
      "           6       1.00      1.00      1.00       100\n",
      "           7       0.60      0.18      0.27        17\n",
      "           8       0.00      0.00      0.00         9\n",
      "           9       0.39      1.00      0.56        11\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.76      0.94      0.84      1358\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.93      0.85      0.89      2032\n",
      "          14       0.88      0.37      0.52        81\n",
      "          15       0.93      0.81      0.87        32\n",
      "          16       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85      4053\n",
      "   macro avg       0.48      0.45      0.43      4053\n",
      "weighted avg       0.85      0.85      0.84      4053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/.pyenv/versions/3.10.6/envs/BImpredict2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/samer/.pyenv/versions/3.10.6/envs/BImpredict2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/samer/.pyenv/versions/3.10.6/envs/BImpredict2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_ready))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BImpredict2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
