{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1fae56",
   "metadata": {},
   "source": [
    "# Bim_Predict NoteBook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d08c1ec",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227613f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define project folder paths\n",
    "# Data directories\n",
    "BASE_DIR = \"../../\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, \"raw_data\")\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, \"processed_data\")\n",
    "PREDICTED_DATA_DIR = os.path.join(DATA_DIR, \"predicting_data\")\n",
    "TESTING_DATA_DIR = os.path.join(DATA_DIR, \"testing_data\")\n",
    "\n",
    "# Model directories\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "ML_MODELS_DIR = os.path.join(MODELS_DIR, \"SK/machine_learning\")\n",
    "DL_MODELS_DIR = os.path.join(MODELS_DIR, \"SK/deep_learning\")\n",
    "OTHER_MODELS_DIR = os.path.join(MODELS_DIR, \"SK/other\")\n",
    "\n",
    "# Python modules and plots directories\n",
    "PYTHON_MODULES_DIR = os.path.join(BASE_DIR, \"python_modules\")\n",
    "PLOTS_DIR = os.path.join(BASE_DIR, \"plots\")\n",
    "\n",
    "# List of directories to create\n",
    "directories = [\n",
    "    RAW_DATA_DIR, PROCESSED_DATA_DIR, PREDICTED_DATA_DIR,\n",
    "    MODELS_DIR, ML_MODELS_DIR, DL_MODELS_DIR, OTHER_MODELS_DIR,\n",
    "    PYTHON_MODULES_DIR, PLOTS_DIR\n",
    "]\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "TARGET_COLUMNS = ['011EC_Lot', '012EC_Ouvrage', '013EC_Localisation', '014EC_Mode_Constructif']\n",
    "exception_keywords = [\"coup√©s\", \"coupants\", \"011EC_Lot\", \"012EC_Ouvrage\", \"013EC_Localisation\", \"014EC_Mode_Constructif\"]\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"Load all test data from Excel files in the testing directory.\"\"\"\n",
    "    test_files = [f for f in os.listdir(TESTING_DATA_DIR) if f.endswith('.xlsx')]\n",
    "\n",
    "    test_data = {}\n",
    "\n",
    "    for file in test_files:\n",
    "        file_path = os.path.join(TESTING_DATA_DIR, file)\n",
    "        print(f\"üì• Loading test file: {file}...\")\n",
    "\n",
    "        # Load all sheets from Excel file\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "            # Ensure it's a valid DataFrame before storing\n",
    "            if not df.empty:\n",
    "                test_data[sheet_name] = {\n",
    "                    'X': df.drop(columns=TARGET_COLUMNS + ['Id'], errors='ignore'),  # Features\n",
    "                    'y': df[TARGET_COLUMNS] if set(TARGET_COLUMNS).issubset(df.columns) else None  # Target\n",
    "                }\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(xls.sheet_names)} sheets from {file}\")\n",
    "\n",
    "    return test_data\n",
    "\n",
    "# Step 1: Import data first\n",
    "test_data = load_test_data()\n",
    "\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Standardize column names by lowercasing and removing special characters.\"\"\"\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.lower()\n",
    "        .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^\\w_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"Drop duplicate rows from DataFrame.\"\"\"\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n",
    "\n",
    "def drop_empty_columns(df, exception_keywords):\n",
    "    \"\"\"Drop columns that are completely missing unless they match exception keywords.\"\"\"\n",
    "    missing_cols = df.columns[df.isnull().mean() == 1]\n",
    "    cols_to_drop = [col for col in missing_cols if not any(keyword in col.lower() for keyword in exception_keywords)]\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Process the data\n",
    "processed_test_data = {}\n",
    "for sheet_name, sheet_dict in test_data.items():\n",
    "    print(f\"üîç Processing sheet: {sheet_name}\")\n",
    "\n",
    "    if isinstance(sheet_dict['X'], pd.DataFrame) and not sheet_dict['X'].empty:\n",
    "        X_test = clean_column_names(sheet_dict['X'])\n",
    "        X_test = remove_duplicates(X_test)\n",
    "        X_test = drop_empty_columns(X_test, exception_keywords)\n",
    "\n",
    "        y_test = sheet_dict['y'] if isinstance(sheet_dict['y'], pd.DataFrame) and not sheet_dict['y'].empty else None\n",
    "\n",
    "        processed_test_data[sheet_name] = {'X': X_test, 'y': y_test}\n",
    "\n",
    "        print(f\"‚úÖ Successfully processed {sheet_name} (Features: {X_test.shape}, Targets: {y_test.shape if y_test is not None else 'N/A'})\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è 'X' is missing or empty for {sheet_name}, skipping preprocessing.\")\n",
    "\n",
    "# Update test_data with processed results\n",
    "test_data = processed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98938bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e19716",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name, sheet_dict in test_data.items():\n",
    "    print(f\"{sheet_name} - Available columns: {sheet_dict['X'].columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "\n",
    "def load_models(models_dir):\n",
    "    \"\"\"Load trained ML and DL models.\"\"\"\n",
    "    models = {'ML': {}, 'DL': {}}\n",
    "\n",
    "    # Load ML models\n",
    "    for model_file in os.listdir(ML_MODELS_DIR):\n",
    "        if model_file.endswith('.joblib') or model_file.endswith('.pkl'):\n",
    "            model_name = os.path.splitext(model_file)[0]\n",
    "            models['ML'][model_name] = joblib.load(os.path.join(ML_MODELS_DIR, model_file))\n",
    "\n",
    "    # Load DL models\n",
    "    for model_file in os.listdir(DL_MODELS_DIR):\n",
    "        model_path = os.path.join(DL_MODELS_DIR, model_file)\n",
    "        if model_file.endswith('.keras') or model_file.endswith('.h5'):\n",
    "            model_name = os.path.splitext(model_file)[0]\n",
    "            models['DL'][model_name] = keras.models.load_model(model_path)\n",
    "        elif os.path.isdir(model_path):\n",
    "            models['DL'][model_file] = keras.models.load_model(model_path)\n",
    "\n",
    "    # Display the number of models and their names\n",
    "    ml_model_count = len(models['ML'])\n",
    "    dl_model_count = len(models['DL'])\n",
    "    print(f\"Imported {ml_model_count} ML models: {list(models['ML'].keys())}\")\n",
    "    print(f\"Imported {dl_model_count} DL models: {list(models['DL'].keys())}\")\n",
    "\n",
    "    return models\n",
    "\n",
    "models = load_models(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for model_name in models['ML']:\n",
    "    preprocessor_path = os.path.join(ML_MODELS_DIR, f\"{model_name}_preprocessor.joblib\")\n",
    "    if not os.path.exists(preprocessor_path):\n",
    "        print(f\"‚ö†Ô∏è Missing preprocessor for {model_name}. Did you save it after training?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def predict_with_models(test_data, models):\n",
    "    \"\"\"Make predictions for all models on test data.\"\"\"\n",
    "    all_results = {}\n",
    "\n",
    "    for sheet_name, data in test_data.items():\n",
    "        print(f\"\\nüîç Processing maquette: {sheet_name}\")\n",
    "        # Check if 'X' and 'y' keys exist in the data dictionary\n",
    "        if 'X' in data and 'y' in data:\n",
    "            X_test = data['X']\n",
    "            y_test = data['y']\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing 'X' or 'y' in test data for sheet: {sheet_name}\")\n",
    "            continue\n",
    "        sheet_results = {}\n",
    "\n",
    "        for model_name, model in models['ML'].items():\n",
    "            try:\n",
    "                print(f\"‚û°Ô∏è Predicting with ML model: {model_name}\")\n",
    "                # Apply preprocessing\n",
    "                preprocessor_path = os.path.join(ML_MODELS_DIR, f\"{model_name}_preprocessor.joblib\")\n",
    "                if os.path.exists(preprocessor_path):\n",
    "                    preprocessor = joblib.load(preprocessor_path)\n",
    "                    X_processed = preprocessor.transform(X_test)\n",
    "                    print(f\"‚úÖ Preprocessing applied using {model_name}_preprocessor.joblib\")\n",
    "                else:\n",
    "                    X_processed = X_test  # Fallback if no preprocessor\n",
    "                    print(f\"‚ö†Ô∏è No preprocessor found for {model_name}, using raw test data\")\n",
    "\n",
    "                # Make predictions\n",
    "                predictions = model.predict(X_processed)\n",
    "\n",
    "                # Convert predictions to human-readable form\n",
    "                readable_predictions = predictions.astype(str)  # Could be adjusted to float/int when necessary\n",
    "\n",
    "                # Evaluate accuracy\n",
    "                evaluation = accuracy_score(y_test, predictions) if y_test is not None else None\n",
    "\n",
    "                # Display predictions and evaluation\n",
    "                print(f\"üìä Predictions: {readable_predictions[:5]}... (showing first 5)\")\n",
    "                if evaluation is not None:\n",
    "                    print(f\"üìà Accuracy: {evaluation:.4f}\")\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è No ground truth provided, skipping evaluation\")\n",
    "\n",
    "                sheet_results[model_name] = {\n",
    "                    'predictions': readable_predictions,\n",
    "                    'evaluation': evaluation\n",
    "                }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error predicting with ML model {model_name}: {str(e)}\")\n",
    "\n",
    "        # Store results per sheet\n",
    "        all_results[sheet_name] = sheet_results\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Call the function and display results\n",
    "all_results = predict_with_models(test_data, models)\n",
    "for maquette, results in all_results.items():\n",
    "    print(f\"\\nüìÑ Results for maquette: {maquette}\")\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"‚û°Ô∏è Model: {model_name}\")\n",
    "        print(f\"   Predictions: {result['predictions'][:5]}... (showing first 5)\")\n",
    "        if result['evaluation'] is not None:\n",
    "            print(f\"   Accuracy: {result['evaluation']:.4f}\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è No ground truth provided, skipping evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea88817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_excel(all_results):\n",
    "    \"\"\"Export all predictions to an Excel file.\"\"\"\n",
    "    for sheet_name, results in all_results.items():\n",
    "        output_dfs = []\n",
    "\n",
    "        for model_name, result in results.items():\n",
    "            pred_df = pd.DataFrame(result['predictions'], columns=[\"Predicted_Value\"])\n",
    "            pred_df[\"Model\"] = model_name\n",
    "            pred_df[\"Evaluation_Accuracy\"] = result['evaluation']\n",
    "\n",
    "            output_dfs.append(pred_df)\n",
    "\n",
    "        if output_dfs:\n",
    "            combined_df = pd.concat(output_dfs)\n",
    "            output_path = os.path.join(PREDICTED_DATA_DIR, f\"{sheet_name}_predictions.xlsx\")\n",
    "            combined_df.to_excel(output_path, index=False)\n",
    "            print(f\"‚úÖ Saved predictions for {sheet_name} to {output_path}\")\n",
    "\n",
    "save_predictions_to_excel(predict_with_models(test_data, models))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BImpredict2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
