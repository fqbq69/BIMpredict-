{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1fae56",
   "metadata": {},
   "source": [
    "# Bim_Predict NoteBook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d08c1ec",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227613f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define project folder paths\n",
    "# Data directories\n",
    "BASE_DIR = \"../../\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, \"raw_data\")\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, \"processed_data\")\n",
    "PREDICTED_DATA_DIR = os.path.join(DATA_DIR, \"predicting_data\")\n",
    "TESTING_DATA_DIR = os.path.join(DATA_DIR, \"testing_data\")\n",
    "\n",
    "# Model directories\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "ML_MODELS_DIR = os.path.join(MODELS_DIR, \"SK/machine_learning\")\n",
    "DL_MODELS_DIR = os.path.join(MODELS_DIR, \"SK/deep_learning\")\n",
    "OTHER_MODELS_DIR = os.path.join(MODELS_DIR, \"SK/other\")\n",
    "\n",
    "# Python modules and plots directories\n",
    "PYTHON_MODULES_DIR = os.path.join(BASE_DIR, \"python_modules\")\n",
    "PLOTS_DIR = os.path.join(BASE_DIR, \"plots\")\n",
    "\n",
    "# List of directories to create\n",
    "directories = [\n",
    "    RAW_DATA_DIR, PROCESSED_DATA_DIR, PREDICTED_DATA_DIR,\n",
    "    MODELS_DIR, ML_MODELS_DIR, DL_MODELS_DIR, OTHER_MODELS_DIR,\n",
    "    PYTHON_MODULES_DIR, PLOTS_DIR\n",
    "]\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMNS = ['011ec_lot', '012ec_ouvrage', '013ec_localisation', '014ec_mode_constructif']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import joblib\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_test_data(file_path):\n",
    "    \"\"\"Load test data from Excel file\"\"\"\n",
    "    try:\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        return {sheet: pd.read_excel(xls, sheet_name=sheet) for sheet in xls.sheet_names}\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def get_test_files():\n",
    "    \"\"\"Get list of test files\"\"\"\n",
    "    return [f for f in os.listdir(TESTING_DATA_DIR) if f.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_test_data(df):\n",
    "    \"\"\"Clean test data with the same logic as training\"\"\"\n",
    "    df = df.copy()\n",
    "    # Your cleaning logic here (same as training)\n",
    "    # Example:\n",
    "    df = df.drop_duplicates()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna('missing')\n",
    "        else:\n",
    "            df[col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "def prepare_features_targets(df):\n",
    "    \"\"\"Separate features and targets\"\"\"\n",
    "    try:\n",
    "        X = df.drop(columns=TARGET_COLUMNS + ['Id'], errors='ignore')\n",
    "        y = df[TARGET_COLUMNS] if all(col in df.columns for col in TARGET_COLUMNS) else None\n",
    "        return X, y\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing columns: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def load_ml_model(model_path):\n",
    "    \"\"\"Load ML model with error handling\"\"\"\n",
    "    try:\n",
    "        return joblib.load(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ML model {model_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_dl_model(model_path):\n",
    "    \"\"\"Load DL model with error handling\"\"\"\n",
    "    try:\n",
    "        return keras.models.load_model(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading DL model {model_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_all_models():\n",
    "    \"\"\"Load all models with their dependencies\"\"\"\n",
    "    models_info = []\n",
    "\n",
    "    # Load ML models\n",
    "    for model_file in os.listdir(ML_MODELS_DIR):\n",
    "        if model_file.endswith(('.joblib', '.pkl')):\n",
    "            model_path = os.path.join(ML_MODELS_DIR, model_file)\n",
    "            model_name = os.path.splitext(model_file)[0]\n",
    "\n",
    "            model = load_ml_model(model_path)\n",
    "            if model is None:\n",
    "                continue\n",
    "\n",
    "            # Try to load preprocessor\n",
    "            preprocessor_path = os.path.join(ML_MODELS_DIR, f\"{model_name}_preprocessor.joblib\")\n",
    "            preprocessor = load_ml_model(preprocessor_path) if os.path.exists(preprocessor_path) else None\n",
    "\n",
    "            models_info.append({\n",
    "                'name': model_name,\n",
    "                'type': 'ML',\n",
    "                'model': model,\n",
    "                'preprocessor': preprocessor\n",
    "            })\n",
    "\n",
    "    # Load DL models\n",
    "    for model_dir in os.listdir(DL_MODELS_DIR):\n",
    "        model_path = os.path.join(DL_MODELS_DIR, model_dir)\n",
    "        if os.path.isdir(model_path):\n",
    "            model = load_dl_model(model_path)\n",
    "            if model is None:\n",
    "                continue\n",
    "\n",
    "            # Try to load preprocessor and label encoders\n",
    "            preprocessor_path = os.path.join(model_path, 'preprocessor.joblib')\n",
    "            preprocessor = load_ml_model(preprocessor_path) if os.path.exists(preprocessor_path) else None\n",
    "\n",
    "            label_encoders_path = os.path.join(model_path, 'label_encoders.joblib')\n",
    "            label_encoders = load_ml_model(label_encoders_path) if os.path.exists(label_encoders_path) else None\n",
    "\n",
    "            models_info.append({\n",
    "                'name': model_dir,\n",
    "                'type': 'DL',\n",
    "                'model': model,\n",
    "                'preprocessor': preprocessor,\n",
    "                'label_encoders': label_encoders\n",
    "            })\n",
    "\n",
    "    return models_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "def predict_ml(model, preprocessor, X_test, label_encoders=None):\n",
    "    \"\"\"Make predictions with ML model\"\"\"\n",
    "    try:\n",
    "        if preprocessor:\n",
    "            X_processed = preprocessor.transform(X_test)\n",
    "        else:\n",
    "            X_processed = X_test\n",
    "\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            preds = model.predict_proba(X_processed)\n",
    "            if preds[0].ndim == 1:  # Binary classification\n",
    "                return preds[:, 1]\n",
    "            else:  # Multiclass\n",
    "                return np.argmax(preds, axis=1)\n",
    "        else:\n",
    "            return model.predict(X_processed)\n",
    "    except Exception as e:\n",
    "        print(f\"ML prediction error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def predict_dl(model, preprocessor, X_test, label_encoders=None):\n",
    "    \"\"\"Make predictions with DL model\"\"\"\n",
    "    try:\n",
    "        if preprocessor:\n",
    "            X_processed = preprocessor.transform(X_test)\n",
    "        else:\n",
    "            X_processed = X_test\n",
    "\n",
    "        preds = model.predict(X_processed)\n",
    "\n",
    "        # Handle different output types\n",
    "        if isinstance(preds, list):  # Multiple outputs\n",
    "            results = {}\n",
    "            for i, target in enumerate(TARGET_COLUMNS[:len(preds)]):\n",
    "                if label_encoders and target in label_encoders:\n",
    "                    results[target] = label_encoders[target].inverse_transform(np.argmax(preds[i], axis=1))\n",
    "                else:\n",
    "                    results[target] = np.argmax(preds[i], axis=1)\n",
    "            return results\n",
    "        else:  # Single output\n",
    "            if preds.ndim > 1 and preds.shape[1] > 1:  # Classification\n",
    "                if label_encoders and TARGET_COLUMNS[0] in label_encoders:\n",
    "                    return label_encoders[TARGET_COLUMNS[0]].inverse_transform(np.argmax(preds, axis=1))\n",
    "                else:\n",
    "                    return np.argmax(preds, axis=1)\n",
    "            else:  # Regression\n",
    "                return preds.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"DL prediction error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, target_name):\n",
    "    \"\"\"Evaluate prediction quality\"\"\"\n",
    "    try:\n",
    "        if y_true.dtype == 'object' or len(np.unique(y_true)) < 20:  # Classification\n",
    "            return accuracy_score(y_true, y_pred)\n",
    "        else:  # Regression\n",
    "            return mean_squared_error(y_true, y_pred)\n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation error for {target_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424182ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def save_predictions(original_df, predictions, model_name, sheet_name, file_name):\n",
    "    \"\"\"Save predictions to Excel with original data\"\"\"\n",
    "    try:\n",
    "        result_df = original_df.copy()\n",
    "\n",
    "        # Add predictions\n",
    "        if isinstance(predictions, dict):  # Multiple targets\n",
    "            for target, pred in predictions.items():\n",
    "                result_df[f'Predicted_{target}'] = pred\n",
    "        else:  # Single target\n",
    "            result_df[f'Predicted_{TARGET_COLUMNS[0]}'] = predictions\n",
    "\n",
    "        # Save to Excel\n",
    "        output_dir = os.path.join(PREDICTED_DATA_DIR, os.path.splitext(file_name)[0])\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"{sheet_name}_{model_name}.xlsx\")\n",
    "        result_df.to_excel(output_path, index=False)\n",
    "\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving predictions: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def generate_summary_report(all_results, output_file='model_performance_summary.json'):\n",
    "    \"\"\"Generate a summary report of model performance\"\"\"\n",
    "    summary = {}\n",
    "\n",
    "    for file_name, file_results in all_results.items():\n",
    "        file_summary = {}\n",
    "\n",
    "        for sheet_name, sheet_results in file_results.items():\n",
    "            sheet_summary = {}\n",
    "\n",
    "            for model_name, model_results in sheet_results.items():\n",
    "                if 'evaluation' in model_results and model_results['evaluation']:\n",
    "                    sheet_summary[model_name] = {\n",
    "                        'metrics': model_results['evaluation'],\n",
    "                        'output_path': model_results.get('output_path', '')\n",
    "                    }\n",
    "                elif 'error' in model_results:\n",
    "                    sheet_summary[model_name] = {\n",
    "                        'error': model_results['error']\n",
    "                    }\n",
    "\n",
    "            if sheet_summary:\n",
    "                file_summary[sheet_name] = sheet_summary\n",
    "\n",
    "        if file_summary:\n",
    "            summary[file_name] = file_summary\n",
    "\n",
    "    # Save summary\n",
    "    with open(os.path.join(PREDICTED_DATA_DIR, output_file), 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    return summary\n",
    "\n",
    "def print_performance_summary(summary):\n",
    "    \"\"\"Print performance summary to console\"\"\"\n",
    "    print(\"\\nTop performing models:\")\n",
    "    for file_name, file_summary in summary.items():\n",
    "        print(f\"\\nFile: {file_name}\")\n",
    "        for sheet_name, sheet_summary in file_summary.items():\n",
    "            print(f\"\\n  Sheet: {sheet_name}\")\n",
    "            for model_name, model_info in sheet_summary.items():\n",
    "                if 'metrics' in model_info:\n",
    "                    avg_score = np.mean(list(model_info['metrics'].values()))\n",
    "                    print(f\"    {model_name}: Average score = {avg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19498a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_test_file(file_path, models_info):\n",
    "    \"\"\"Process a single test file through all models\"\"\"\n",
    "    results = {}\n",
    "    test_data = load_test_data(file_path)\n",
    "\n",
    "    for sheet_name, df in test_data.items():\n",
    "        sheet_results = {}\n",
    "        df_clean = clean_test_data(df)\n",
    "        X_test, y_test = prepare_features_targets(df_clean)\n",
    "\n",
    "        if X_test is None:\n",
    "            continue\n",
    "\n",
    "        for model_info in models_info:\n",
    "            model_name = model_info['name']\n",
    "            model_type = model_info['type']\n",
    "            predictions = None\n",
    "\n",
    "            try:\n",
    "                if model_type == 'ML':\n",
    "                    predictions = predict_ml(\n",
    "                        model_info['model'],\n",
    "                        model_info.get('preprocessor'),\n",
    "                        X_test,\n",
    "                        model_info.get('label_encoders')\n",
    "                    )\n",
    "                elif model_type == 'DL':\n",
    "                    predictions = predict_dl(\n",
    "                        model_info['model'],\n",
    "                        model_info.get('preprocessor'),\n",
    "                        X_test,\n",
    "                        model_info.get('label_encoders')\n",
    "                    )\n",
    "\n",
    "                # Evaluate if we have ground truth\n",
    "                evaluation = {}\n",
    "                if y_test is not None and predictions is not None:\n",
    "                    if isinstance(predictions, dict):  # Multiple targets\n",
    "                        for target, pred in predictions.items():\n",
    "                            evaluation[target] = evaluate_predictions(y_test[target], pred, target)\n",
    "                    else:  # Single target\n",
    "                        evaluation[TARGET_COLUMNS[0]] = evaluate_predictions(\n",
    "                            y_test[TARGET_COLUMNS[0]], predictions, TARGET_COLUMNS[0])\n",
    "\n",
    "                # Save predictions\n",
    "                output_path = save_predictions(\n",
    "                    df_clean,\n",
    "                    predictions,\n",
    "                    model_name,\n",
    "                    sheet_name,\n",
    "                    os.path.basename(file_path)\n",
    "                )\n",
    "\n",
    "                sheet_results[model_name] = {\n",
    "                    'predictions': predictions,\n",
    "                    'evaluation': evaluation,\n",
    "                    'output_path': output_path\n",
    "                }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {model_name} on {sheet_name}: {str(e)}\")\n",
    "                sheet_results[model_name] = {\n",
    "                    'error': str(e)\n",
    "                }\n",
    "\n",
    "        results[sheet_name] = sheet_results\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Create output directory\n",
    "    os.makedirs(PREDICTED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "    # Load all models\n",
    "    models_info = load_all_models()\n",
    "    print(f\"Loaded {len(models_info)} models\")\n",
    "\n",
    "    # Process all test files\n",
    "    test_files = get_test_files()\n",
    "    all_results = {}\n",
    "\n",
    "    for test_file in tqdm(test_files, desc=\"Processing test files\"):\n",
    "        file_path = os.path.join(TESTING_DATA_DIR, test_file)\n",
    "        results = process_test_file(file_path, models_info)\n",
    "        all_results[test_file] = results\n",
    "\n",
    "    # Generate and display summary\n",
    "    summary = generate_summary_report(all_results)\n",
    "    print(\"\\nModel performance summary saved to PREDICTED_DATA/model_performance_summary.json\")\n",
    "    print_performance_summary(summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BImpredict2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
