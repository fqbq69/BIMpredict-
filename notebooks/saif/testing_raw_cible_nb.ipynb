{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a3dbdd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Testing Raw Cible WB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088204a",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dfa8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ====================\n",
    "### Importing libraries\n",
    "### ====================\n",
    "# %matplotlib inline\n",
    "# %pip install openpyxl\n",
    "import openpyxl\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# import shap\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "### ====================\n",
    "### Set up visualization and warnings\n",
    "### ====================\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_palette('viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53d491bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ====================\n",
    "### File paths\n",
    "###  ===================\n",
    "# Create directories for model saving\n",
    "models_dir = '../../models'\n",
    "for model_type in ['simple_models', 'ml_models', 'dl_models']:\n",
    "    models_dir = os.path.join(models_dir, model_type)\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Load Excel file\n",
    "maquettes_path = \"../../data/raw/\"\n",
    "maquettes= [\"RawData-Cibles.xlsx\"]\n",
    "for maquette in maquettes:\n",
    "    maquettes_path = os.path.join(maquettes_path, maquette)\n",
    "sheets = [\"Mur\", \"Sols\", \"Poutre\", \"Poteaux\"]  # Adjusted based on your description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72fbf0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from the Excel file.\n",
      "Murs DataFrame Shape: (312, 96)\n",
      "Sols DataFrame Shape: (107, 94)\n",
      "Poutres DataFrame Shape: (246, 100)\n",
      "Poteaux DataFrame Shape: (68, 87)\n",
      "\n",
      "Murs DataFrame Preview:\n",
      "Index(['Id', '011EC_Lot', '012EC_Ouvrage', '013EC_Localisation',\n",
      "       '014EC_Mode Constructif', 'Nom', 'Hauteur', 'Epaisseur', 'AI', 'AS',\n",
      "       'Sols en intersection', 'Sols coupés (u)', 'Sols coupés (Ids)',\n",
      "       'Sols coupants (u)', 'Sols coupants (Ids)', 'Sol au-dessus',\n",
      "       'Sol en-dessous', 'Fenêtres', 'Portes', 'Ouvertures', 'Murs imbriqués',\n",
      "       'Mur multicouche', 'Mur empilé', 'Profil modifié', 'Image', 'Catégorie',\n",
      "       'Section', 'Type prédéfini d'IFC', 'Exporter au format IFC sous',\n",
      "       'Exporter au format IFC', 'IfcGUID', 'A une association',\n",
      "       'Enrobage d'armature - Autres faces',\n",
      "       'Enrobage d'armature - Face intérieure',\n",
      "       'Enrobage d'armature - Face extérieure', 'Variantes',\n",
      "       'Extension inférieure', 'Extension supérieure', 'Volume', 'Surface',\n",
      "       'Phase de démolition', 'Phase de création', 'Commentaires', 'Longueur',\n",
      "       'Famille et type', 'Famille', 'Type', 'Nom de la famille',\n",
      "       'Nom du type', 'ID du type', 'Lié au volume', 'Structure',\n",
      "       'Identifiant', 'Ligne de justification', 'Utilisation structurelle',\n",
      "       'Partie inférieure attachée', 'Partie supérieure attachée',\n",
      "       'Décalage supérieur', 'Décalage inférieur', 'Contrainte inférieure',\n",
      "       'Hauteur non contrainte', 'Contrainte supérieure', 'Limite de pièce',\n",
      "       'Nature_Ouvrage', 'Batiment', 'Mur armé', 'Affichage poteau',\n",
      "       'NIVEAU_STRUCTURE', 'Image du type', 'Note d'identification',\n",
      "       'Type: Type prédéfini d'IFC', 'Exporter le type au format IFC sous',\n",
      "       'Exporter le type au format IFC', 'Type IfcGUID', 'Modèle', 'Fabricant',\n",
      "       'Commentaires du type', 'URL', 'Description', 'Matériau structurel',\n",
      "       'Rugosité', 'Coefficient d'absorbance', 'Masse thermique',\n",
      "       'Résistance thermique (R)', 'Coefficient de transfert thermique (U)',\n",
      "       'Description de l'assemblage', 'Code d'assemblage',\n",
      "       'Retournement aux insertions', 'Retournement aux extrémités',\n",
      "       'Couleur vue détail faible', 'Motif vue détail faible',\n",
      "       'Marque de type', 'Protection contre l'incendie', 'Coût', 'Fonction',\n",
      "       'Largeur'],\n",
      "      dtype='object')\n",
      "\n",
      "Sols DataFrame Preview:\n",
      "Index(['Id', '011EC_Lot', '012EC_Ouvrage', '013EC_Localisation',\n",
      "       '014EC_Mode Constructif', 'Nom', 'Murs en intersection',\n",
      "       'Murs coupés (u)', 'Murs coupés (Ids)', 'Murs coupants (u)',\n",
      "       'Murs coupants (Ids)', 'Poutres en intersection', 'Poutres coupés (u)',\n",
      "       'Poutres coupés (Ids)', 'Poutres coupants (u)',\n",
      "       'Poutres coupants (Ids)', 'Poteaux en intersection',\n",
      "       'Poteaux coupés (u)', 'Poteaux coupés (Ids)', 'Poteaux coupants (u)',\n",
      "       'Poteaux coupants (Ids)', 'Ouvertures', 'Sol multicouche',\n",
      "       'Profil modifié', 'Image', 'Catégorie', 'Type prédéfini d'IFC',\n",
      "       'Exporter au format IFC sous', 'Exporter au format IFC', 'IfcGUID',\n",
      "       'A une association', 'Enrobage d'armature - Face inférieure',\n",
      "       'Enrobage d'armature - Face supérieure',\n",
      "       'Enrobage d'armature - Autres faces', 'Variantes', 'Volume', 'Surface',\n",
      "       'Phase de démolition', 'Phase de création', 'Commentaires',\n",
      "       'Inclinaison', 'Niveau', 'Famille et type', 'Famille', 'Type',\n",
      "       'Nom de la famille', 'Nom du type', 'ID du type', 'Structure',\n",
      "       'Périmètre', 'Décalage par rapport au niveau', 'Epaisseur',\n",
      "       'Lié au volume', 'Etude de l'élévation à la base',\n",
      "       'Etude de l'élévation en haut', 'Epaisseur du porteur',\n",
      "       'Elévation au niveau du noyau inférieur',\n",
      "       'Elévation au niveau du noyau supérieur', 'Elévation en haut',\n",
      "       'Elévation à la base', 'Identifiant', 'Limite de pièce',\n",
      "       'Nature_Ouvrage', 'Batiment', 'Niveau fini', 'Niveau Brut',\n",
      "       'NIVEAU_STRUCTURE', 'Image du type', 'Note d'identification',\n",
      "       'Type: Type prédéfini d'IFC', 'Exporter le type au format IFC sous',\n",
      "       'Exporter le type au format IFC', 'Type IfcGUID', 'Modèle', 'Fabricant',\n",
      "       'Commentaires du type', 'URL', 'Description', 'Matériau structurel',\n",
      "       'Rugosité', 'Coefficient d'absorbance', 'Masse thermique',\n",
      "       'Résistance thermique (R)', 'Coefficient de transfert thermique (U)',\n",
      "       'Description de l'assemblage', 'Code d'assemblage',\n",
      "       'Couleur vue détail faible', 'Motif vue détail faible',\n",
      "       'Epaisseur par défaut', 'Marque de type', 'Coût', 'Fonction',\n",
      "       'épaisseur', 'Condition de bord incurvé'],\n",
      "      dtype='object')\n",
      "\n",
      "Poutres DataFrame Preview:\n",
      "Index(['Id', '011EC_Lot', '012EC_Ouvrage', '013EC_Localisation',\n",
      "       '014EC_Mode Constructif', 'Nom', 'AI', 'AS', 'Hauteur totale',\n",
      "       'Hauteur', 'Sols en intersection', 'Sols coupés (u)',\n",
      "       'Sols coupés (Ids)', 'Sols coupants (u)', 'Sols coupants (Ids)',\n",
      "       'Sol au-dessus', 'Sol en-dessous', 'Poteaux en intersection',\n",
      "       'Poteaux coupés (u)', 'Poteaux coupés (Ids)', 'Poteaux coupants (u)',\n",
      "       'Poteaux coupants (Ids)', 'Image', 'Etat de la jonction',\n",
      "       'Valeur de décalage Z', 'Justification Z', 'Valeur de décalage Y',\n",
      "       'Justification Y', 'Justification YZ', 'Catégorie',\n",
      "       'Type prédéfini d'IFC', 'Exporter au format IFC sous',\n",
      "       'Exporter au format IFC', 'IfcGUID', 'A une association',\n",
      "       'Enrobage d'armature - Face inférieure',\n",
      "       'Enrobage d'armature - Face supérieure',\n",
      "       'Enrobage d'armature - Autres faces', 'Variantes', 'Volume',\n",
      "       'Phase de démolition', 'Phase de création', 'Commentaires',\n",
      "       'Matériau structurel', 'ID hôte', 'Niveau', 'Famille et type',\n",
      "       'Famille', 'Type', 'Nom de la famille', 'Nom du type', 'ID du type',\n",
      "       'Elévation du niveau de référence', 'Elévation en haut',\n",
      "       'Rotation de la section', 'Orientation', 'Décalage du niveau d'arrivée',\n",
      "       'Décalage du niveau de départ', 'Elévation à la base',\n",
      "       'Longueur de coupe', 'Niveau de référence', 'Utilisation structurelle',\n",
      "       'Plan de construction', 'Longueur', 'Identifiant', 'Nature_Ouvrage',\n",
      "       'Batiment', 'Perimetre coffrage', 'Vtotal', 'hauteur_section',\n",
      "       'largeur_section', 'NIVEAU_STRUCTURE', 'Image du type',\n",
      "       'Note d'identification', 'Type: Type prédéfini d'IFC',\n",
      "       'Exporter le type au format IFC sous', 'Exporter le type au format IFC',\n",
      "       'Type IfcGUID', 'Modèle', 'Fabricant', 'Commentaires du type', 'URL',\n",
      "       'Description', 'Nom de code', 'Identifiant du nom de la coupe',\n",
      "       'Forme de coupe', 'Titre OmniClass', 'Numéro OmniClass',\n",
      "       'Description de l'assemblage', 'Code d'assemblage', 'Marque de type',\n",
      "       'Protection contre l'incendie', 'Coût', 'h', 'b', 'Type Ossature',\n",
      "       'Type d'attachement de fin', 'Type d'attachement de début',\n",
      "       'LG_DECAISSE', 'ht-decaisse'],\n",
      "      dtype='object')\n",
      "\n",
      "Poteaux DataFrame Preview:\n",
      "Index(['Id', '011EC_Lot', '012EC_Ouvrage', '013EC_Localisation',\n",
      "       '014EC_Mode Constructif', 'Nom', 'AI', 'AS', 'Hauteur', 'Longueur',\n",
      "       'Partie inférieure attachée', 'Partie supérieure attachée',\n",
      "       'Sols en intersection', 'Sols coupés (u)', 'Sols coupés (Ids)',\n",
      "       'Sols coupants (u)', 'Sols coupants (Ids)', 'Poutres en intersection',\n",
      "       'Poutres coupés (u)', 'Poutres coupés (Ids)', 'Poutres coupants (u)',\n",
      "       'Poutres coupants (Ids)', 'Image', 'Style de poteau', 'Catégorie',\n",
      "       'Type prédéfini d'IFC', 'Exporter au format IFC sous',\n",
      "       'Exporter au format IFC', 'IfcGUID', 'A une association',\n",
      "       'Enrobage d'armature - Face inférieure',\n",
      "       'Enrobage d'armature - Face supérieure',\n",
      "       'Enrobage d'armature - Autres faces', 'Variantes', 'Volume',\n",
      "       'Phase de démolition', 'Phase de création', 'Commentaires',\n",
      "       'Matériau structurel', 'Marque d'emplacement du poteau', 'ID hôte',\n",
      "       'Décalage supérieur', 'Décalage inférieur', 'Niveau supérieur',\n",
      "       'Niveau de base', 'Niveau', 'Famille et type', 'Famille', 'Type',\n",
      "       'Nom de la famille', 'Nom du type', 'ID du type',\n",
      "       'Se déplace avec les quadrillages', 'Identifiant', 'Limite de pièce',\n",
      "       'Batiment', 'NIVEAU_STRUCTURE', 'Image du type',\n",
      "       'Note d'identification', 'Type: Type prédéfini d'IFC',\n",
      "       'Exporter le type au format IFC sous', 'Exporter le type au format IFC',\n",
      "       'Type IfcGUID', 'Modèle', 'Fabricant', 'Commentaires du type', 'URL',\n",
      "       'Description', 'Nom de code', 'Identifiant du nom de la coupe',\n",
      "       'Forme de coupe', 'Titre OmniClass', 'Numéro OmniClass',\n",
      "       'Description de l'assemblage', 'Code d'assemblage', 'Marque de type',\n",
      "       'Coût', 'Nature_Ouvrage', 'Diamètre poteau', 'h', 'b',\n",
      "       'hauteur_section', 'largeur_section',\n",
      "       'Décalage de l'attachement à la base',\n",
      "       'Justification de l'attachement en bas',\n",
      "       'Décalage de l'attachement en haut',\n",
      "       'Justification de l'attachement en haut'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### ====================\n",
    "### import data from the Excel file\n",
    "### ====================\n",
    "try:\n",
    "    murs_df = pd.read_excel(maquettes_path, sheet_name='Murs')\n",
    "    sols_df = pd.read_excel(maquettes_path, sheet_name='Sols')\n",
    "    poutres_df = pd.read_excel(maquettes_path, sheet_name='Poutres')\n",
    "    poteaux_df = pd.read_excel(maquettes_path, sheet_name='Poteaux')\n",
    "    print(\"Data loaded successfully from the Excel file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Handle missing sheets\n",
    "    available_sheets = pd.ExcelFile(maquettes_path).sheet_names\n",
    "    print(f\"Available sheets: {available_sheets}\")\n",
    "    # Try to load available sheets\n",
    "    dfs = {}\n",
    "    for sheet in sheets:\n",
    "        if sheet in available_sheets:\n",
    "            dfs[sheet] = pd.read_excel(maquettes_path, sheet_name=sheet)\n",
    "        else:\n",
    "            print(f\"Sheet '{sheet}' not found in the Excel file.\")\n",
    "    mur_df = dfs.get('Murs', pd.DataFrame())\n",
    "    sol_df = dfs.get('Sols', pd.DataFrame())\n",
    "    poutres_df = dfs.get('Poutres', pd.DataFrame())\n",
    "    poteaux_df = dfs.get('Poteaux', pd.DataFrame())\n",
    "\n",
    "# Display basic info about each dataframe\n",
    "print(\"Murs DataFrame Shape:\", murs_df.shape)\n",
    "print(\"Sols DataFrame Shape:\", sols_df.shape)\n",
    "print(\"Poutres DataFrame Shape:\", poutres_df.shape)\n",
    "print(\"Poteaux DataFrame Shape:\", poteaux_df.shape)\n",
    "\n",
    "# Display the first few rows of each dataframe\n",
    "print(\"\\nMurs DataFrame Preview:\")\n",
    "print(murs_df.columns)\n",
    "print(\"\\nSols DataFrame Preview:\")\n",
    "print(sols_df.columns)\n",
    "print(\"\\nPoutres DataFrame Preview:\")\n",
    "print(poutres_df.columns)\n",
    "print(\"\\nPoteaux DataFrame Preview:\")\n",
    "print(poteaux_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd8d5c",
   "metadata": {},
   "source": [
    "## Part 2: Data Preprocessing and Relationship Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49991be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ====================\n",
    "### Define essential columns for each DataFrame\n",
    "### ====================\n",
    "ESSENTIAL_COLUMNS = {\n",
    "    \"Murs\": [\n",
    "        \"Id\", \"011EC_Lot\", \"012EC_Ouvrage\", \"013EC_Localisation\", \"014EC_Mode Constructif\", \"Hauteur\", \"Epaisseur\", \"AI\", \"AS\", \"Sols en intersection\", \"Sols coupés (u)\", \"Sols coupés (Ids)\",\n",
    "        \"Sols coupants (u)\", \"Sols coupants (Ids)\", \"Sol au-dessus\", \"Sol en-dessous\", \"Fenêtres\", \"Portes\", \"Ouvertures\", \"Murs imbriqués\",\n",
    "        \"Mur multicouche\", \"Profil modifié\", \"Extension inférieure\", \"Extension supérieure\", \"Volume\", \"Surface\", \"Partie inférieure attachée\", \"Partie supérieure attachée\",\n",
    "        \"Décalage supérieur\", \"Décalage inférieur\", \"Matériau structurel\",\n",
    "    ],\n",
    "    \"Sols\": [\n",
    "        \"Id\", \"011EC_Lot\", \"012EC_Ouvrage\", \"013EC_Localisation\", \"014EC_Mode Constructif\", \"Murs en intersection\",\n",
    "        \"Murs coupés (u)\", \"Murs coupés (Ids)\", \"Murs coupants (u)\", \"Murs coupants (Ids)\", \"Poutres en intersection\", \"Poutres coupés (u)\",\n",
    "        \"Poutres coupés (Ids)\", \"Poutres coupants (u)\", \"Poutres coupants (Ids)\", \"Poteaux en intersection\",\n",
    "        \"Poteaux coupés (u)\", \"Poteaux coupés (Ids)\", \"Poteaux coupants (u)\", \"Poteaux coupants (Ids)\", \"Volume\", \"Surface\", \"Matériau structurel\",\n",
    "    ],\n",
    "    \"Poutres\": [\n",
    "        \"Id\", \"011EC_Lot\", \"012EC_Ouvrage\", \"013EC_Localisation\", \"014EC_Mode Constructif\", \"AI\", \"AS\", \"Hauteur totale\", \"Hauteur\", \"Sols en intersection\", \"Sols coupés (u)\",\n",
    "        \"Sols coupés (Ids)\", \"Sols coupants (u)\", \"Sols coupants (Ids)\", \"Sol au-dessus\", \"Sol en-dessous\", \"Poteaux en intersection\",\n",
    "        \"Poteaux coupés (u)\", \"Poteaux coupés (Ids)\", \"Poteaux coupants (u)\", \"Matériau structurel\",\n",
    "        \"Poteaux coupants (Ids)\", \"Elévation à la base\", \"Longueur de coupe\",\n",
    "    ],\n",
    "    \"Poteaux\": [\n",
    "        \"Id\", \"011EC_Lot\", \"012EC_Ouvrage\", \"013EC_Localisation\", \"014EC_Mode Constructif\", \"Nom\", \"AI\", \"AS\", \"Hauteur\", \"Longueur\",\n",
    "        \"Partie inférieure attachée\", \"Partie supérieure attachée\", \"Sols en intersection\", \"Sols coupés (u)\", \"Sols coupés (Ids)\",\n",
    "        \"Sols coupants (u)\", \"Sols coupants (Ids)\", \"Poutres en intersection\", \"Poutres coupés (u)\", \"Poutres coupés (Ids)\", \"Poutres coupants (u)\",\n",
    "        \"Poutres coupants (Ids)\", \"Matériau structurel\", \"Marque d'emplacement du poteau\", \"Décalage supérieur\", \"Décalage inférieur\",\n",
    "        \"Longueur\", \"Sols coupés (Ids)\", \"Sols coupants (Ids)\", \"Poutres coupés (Ids)\", \"Poutres coupants (Ids)\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ====================\n",
    "### Data Loading and Cleaning\n",
    "### ====================\n",
    "def load_and_clean_data(filepath):\n",
    "    \"\"\"Load and clean data with robust column name handling\"\"\"\n",
    "    dfs = {}\n",
    "\n",
    "    try:\n",
    "        xls = pd.ExcelFile(filepath)\n",
    "        available_sheets = xls.sheet_names\n",
    "\n",
    "        for sheet, keep_cols in ESSENTIAL_COLUMNS.items():\n",
    "            if sheet in available_sheets:\n",
    "                # Load and clean\n",
    "                df = pd.read_excel(filepath, sheet_name=sheet)\n",
    "                df.columns = (df.columns\n",
    "                            .str.strip()\n",
    "                            .str.replace('\\s+', ' ', regex=True)\n",
    "                            )\n",
    "\n",
    "                # Select columns\n",
    "                existing_cols = [col.strip() for col in keep_cols if col.strip() in df.columns]\n",
    "                missing_cols = set(col.strip() for col in keep_cols) - set(existing_cols)\n",
    "\n",
    "                if missing_cols:\n",
    "                    print(f\"⚠️ {sheet}: Missing {len(missing_cols)} columns: {list(missing_cols)[:3]}{'...' if len(missing_cols)>3 else ''}\")\n",
    "\n",
    "                dfs[sheet] = df[existing_cols]\n",
    "                print(f\"✅ {sheet}: Kept {len(existing_cols)}/{len(keep_cols)} columns | New shape: {dfs[sheet].shape}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Sheet '{sheet}' not found\")\n",
    "                dfs[sheet] = pd.DataFrame()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Error: {str(e)[:100]}...\")\n",
    "        dfs = {sheet: pd.DataFrame() for sheet in ESSENTIAL_COLUMNS.keys()}\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38a3e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ====================\n",
    "### Verify that all critical columns are present\n",
    "### ====================\n",
    "CRITICAL_COLUMNS = [\"011EC_Lot\", \"012EC_Ouvrage\", \"013EC_Localisation\", \"014EC_Mode Constructif\"]\n",
    "\n",
    "for sheet, df in dataframes.items():\n",
    "    missing_critical = [col for col in CRITICAL_COLUMNS if col not in df.columns]\n",
    "    if missing_critical:\n",
    "        print(f\"🚨 Critical columns missing in {sheet}: {missing_critical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c47058e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Murs: Kept 31/31 columns | New shape: (312, 31)\n",
      "✅ Sols: Kept 24/24 columns | New shape: (107, 24)\n",
      "✅ Poutres: Kept 24/24 columns | New shape: (246, 24)\n",
      "✅ Poteaux: Kept 31/31 columns | New shape: (68, 31)\n",
      "\n",
      "Cleaned DataFrame Shapes:\n",
      "Murs: (312, 31)\n",
      "Sols: (107, 24)\n",
      "Poutres: (246, 24)\n",
      "Poteaux: (68, 31)\n"
     ]
    }
   ],
   "source": [
    "### ====================\n",
    "### Cleaned DataFrames Loading\n",
    "### ====================\n",
    "dataframes = load_and_clean_data(maquettes_path)\n",
    "\n",
    "# Access the cleaned DataFrames\n",
    "murs_df = dataframes['Murs']\n",
    "sols_df = dataframes['Sols']\n",
    "poutre_df = dataframes['Poutres']\n",
    "poteaux_df = dataframes['Poteaux']\n",
    "\n",
    "# Verify the results\n",
    "print(\"\\nCleaned DataFrame Shapes:\")\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb458ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔍 Processing Murs\n",
      "==================================================\n",
      "\n",
      "🔹 Column Pair: Sols coupés (u) → Sols coupés (Ids)\n",
      "BEFORE:    Sols coupés (u) Sols coupés (Ids)\n",
      "0                0                []\n",
      "1                0                []\n",
      "2                0                []\n",
      "AFTER:    Sols coupés (u) Sols coupés (Ids)\n",
      "0                0                []\n",
      "1                0                []\n",
      "2                0                []\n",
      "\n",
      "🔹 Column Pair: Sols coupants (u) → Sols coupants (Ids)\n",
      "BEFORE:    Sols coupants (u)          Sols coupants (Ids)\n",
      "0                  3  [1788267, 1788458, 1790282]\n",
      "1                  1                    [1788267]\n",
      "2                  1                    [1788267]\n",
      "AFTER:    Sols coupants (u)          Sols coupants (Ids)\n",
      "0                  3  [1788267, 1788458, 1790282]\n",
      "1                  1                    [1788267]\n",
      "2                  1                    [1788267]\n",
      "🚨 Skipping: Murs coupés (u) or Murs coupés (Ids) not found in Murs\n",
      "🚨 Skipping: Murs coupants (u) or Murs coupants (Ids) not found in Murs\n",
      "🚨 Skipping: Poutres coupés (u) or Poutres coupés (Ids) not found in Murs\n",
      "🚨 Skipping: Poutres coupants (u) or Poutres coupants (Ids) not found in Murs\n",
      "🚨 Skipping: Poteaux coupés (u) or Poteaux coupés (Ids) not found in Murs\n",
      "🚨 Skipping: Poteaux coupants (u) or Poteaux coupants (Ids) not found in Murs\n",
      "\n",
      "==================================================\n",
      "🔍 Processing Sols\n",
      "==================================================\n",
      "🚨 Skipping: Sols coupés (u) or Sols coupés (Ids) not found in Sols\n",
      "🚨 Skipping: Sols coupants (u) or Sols coupants (Ids) not found in Sols\n",
      "\n",
      "🔹 Column Pair: Murs coupés (u) → Murs coupés (Ids)\n",
      "BEFORE:    Murs coupés (u)                                  Murs coupés (Ids)\n",
      "0                0                                                 []\n",
      "1                9  [1787858, 1787860, 1787874, 1789104, 1789106, ...\n",
      "2                3                        [1788054, 1789308, 1794860]\n",
      "AFTER:    Murs coupés (u)                                  Murs coupés (Ids)\n",
      "0                0                                                 []\n",
      "1                9  [1787858, 1787860, 1787874, 1789104, 1789106, ...\n",
      "2                3                        [1788054, 1789308, 1794860]\n",
      "\n",
      "🔹 Column Pair: Murs coupants (u) → Murs coupants (Ids)\n",
      "BEFORE:    Murs coupants (u) Murs coupants (Ids)\n",
      "0                  0                  []\n",
      "1                  0                  []\n",
      "2                  0                  []\n",
      "AFTER:    Murs coupants (u) Murs coupants (Ids)\n",
      "0                  0                  []\n",
      "1                  0                  []\n",
      "2                  0                  []\n",
      "\n",
      "🔹 Column Pair: Poutres coupés (u) → Poutres coupés (Ids)\n",
      "BEFORE:    Poutres coupés (u) Poutres coupés (Ids)\n",
      "0                   1            [1793428]\n",
      "1                   1            [1788274]\n",
      "2                   0                   []\n",
      "AFTER:    Poutres coupés (u) Poutres coupés (Ids)\n",
      "0                   1            [1793428]\n",
      "1                   1            [1788274]\n",
      "2                   0                   []\n",
      "\n",
      "🔹 Column Pair: Poutres coupants (u) → Poutres coupants (Ids)\n",
      "BEFORE:    Poutres coupants (u) Poutres coupants (Ids)\n",
      "0                     0                     []\n",
      "1                     0                     []\n",
      "2                     0                     []\n",
      "AFTER:    Poutres coupants (u) Poutres coupants (Ids)\n",
      "0                     0                     []\n",
      "1                     0                     []\n",
      "2                     0                     []\n",
      "\n",
      "🔹 Column Pair: Poteaux coupés (u) → Poteaux coupés (Ids)\n",
      "BEFORE:    Poteaux coupés (u) Poteaux coupés (Ids)\n",
      "0                   0                   []\n",
      "1                   0                   []\n",
      "2                   0                   []\n",
      "AFTER:    Poteaux coupés (u) Poteaux coupés (Ids)\n",
      "0                   0                   []\n",
      "1                   0                   []\n",
      "2                   0                   []\n",
      "\n",
      "🔹 Column Pair: Poteaux coupants (u) → Poteaux coupants (Ids)\n",
      "BEFORE:    Poteaux coupants (u) Poteaux coupants (Ids)\n",
      "0                     0                     []\n",
      "1                     0                     []\n",
      "2                     0                     []\n",
      "AFTER:    Poteaux coupants (u) Poteaux coupants (Ids)\n",
      "0                     0                     []\n",
      "1                     0                     []\n",
      "2                     0                     []\n",
      "\n",
      "==================================================\n",
      "🔍 Processing Poutres\n",
      "==================================================\n",
      "\n",
      "🔹 Column Pair: Sols coupés (u) → Sols coupés (Ids)\n",
      "BEFORE:    Sols coupés (u) Sols coupés (Ids)\n",
      "0                0                []\n",
      "1                0                []\n",
      "2                0                []\n",
      "AFTER:    Sols coupés (u) Sols coupés (Ids)\n",
      "0                0                []\n",
      "1                0                []\n",
      "2                0                []\n",
      "\n",
      "🔹 Column Pair: Sols coupants (u) → Sols coupants (Ids)\n",
      "BEFORE:    Sols coupants (u) Sols coupants (Ids)\n",
      "0                  0                  []\n",
      "1                  0                  []\n",
      "2                  0                  []\n",
      "AFTER:    Sols coupants (u) Sols coupants (Ids)\n",
      "0                  0                  []\n",
      "1                  0                  []\n",
      "2                  0                  []\n",
      "🚨 Skipping: Murs coupés (u) or Murs coupés (Ids) not found in Poutres\n",
      "🚨 Skipping: Murs coupants (u) or Murs coupants (Ids) not found in Poutres\n",
      "🚨 Skipping: Poutres coupés (u) or Poutres coupés (Ids) not found in Poutres\n",
      "🚨 Skipping: Poutres coupants (u) or Poutres coupants (Ids) not found in Poutres\n",
      "\n",
      "🔹 Column Pair: Poteaux coupés (u) → Poteaux coupés (Ids)\n",
      "BEFORE:    Poteaux coupés (u) Poteaux coupés (Ids)\n",
      "0                   0                   []\n",
      "1                   0                   []\n",
      "2                   0                   []\n",
      "AFTER:    Poteaux coupés (u) Poteaux coupés (Ids)\n",
      "0                   0                   []\n",
      "1                   0                   []\n",
      "2                   0                   []\n",
      "\n",
      "🔹 Column Pair: Poteaux coupants (u) → Poteaux coupants (Ids)\n",
      "BEFORE:    Poteaux coupants (u) Poteaux coupants (Ids)\n",
      "0                     0                     []\n",
      "1                     0                     []\n",
      "2                     0                     []\n",
      "AFTER:    Poteaux coupants (u) Poteaux coupants (Ids)\n",
      "0                     0                     []\n",
      "1                     0                     []\n",
      "2                     0                     []\n",
      "\n",
      "==================================================\n",
      "🔍 Processing Poteaux\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 53\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Usage Example\u001b[39;00m\n\u001b[1;32m     46\u001b[0m df_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMurs\u001b[39m\u001b[38;5;124m'\u001b[39m: murs_df,\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSols\u001b[39m\u001b[38;5;124m'\u001b[39m: sols_df,\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoutres\u001b[39m\u001b[38;5;124m'\u001b[39m: poutres_df,\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoteaux\u001b[39m\u001b[38;5;124m'\u001b[39m: poteaux_df\n\u001b[1;32m     51\u001b[0m }\n\u001b[0;32m---> 53\u001b[0m cleaned_dfs \u001b[38;5;241m=\u001b[39m \u001b[43mclean_id_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Update DataFrames\u001b[39;00m\n\u001b[1;32m     56\u001b[0m murs_df \u001b[38;5;241m=\u001b[39m cleaned_dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMurs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[47], line 35\u001b[0m, in \u001b[0;36mclean_id_columns\u001b[0;34m(df_dict)\u001b[0m\n\u001b[1;32m     32\u001b[0m df[ids_col] \u001b[38;5;241m=\u001b[39m df[ids_col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mna\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Apply cleaning condition\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m condition \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mids_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[condition, ids_col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Set IDs to \"0\" when u = 0 and Ids is empty\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Show before/after for a few sample rows\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/arraylike.py:76\u001b[0m, in \u001b[0;36mOpsMixin.__rand__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__rand__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__rand__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logical_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/frame.py:7592\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7589\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[1;32m   7590\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m-> 7592\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_method_FRAME\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   7594\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   7595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/ops/__init__.py:307\u001b[0m, in \u001b[0;36malign_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mequals(right\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m    298\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    299\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomatic reindexing on DataFrame vs Series comparisons \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis deprecated and will raise ValueError in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    305\u001b[0m             )\n\u001b[0;32m--> 307\u001b[0m     left, right \u001b[38;5;241m=\u001b[39m \u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     right \u001b[38;5;241m=\u001b[39m _maybe_align_series_as_frame(left, right, axis)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m left, right\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/frame.py:5090\u001b[0m, in \u001b[0;36mDataFrame.align\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   5076\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39malign, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_shared_doc_kwargs)\n\u001b[1;32m   5077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21malign\u001b[39m(\n\u001b[1;32m   5078\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5088\u001b[0m     broadcast_axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5089\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 5090\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5093\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5094\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbroadcast_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbroadcast_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/generic.py:9452\u001b[0m, in \u001b[0;36mNDFrame.align\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   9440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(\n\u001b[1;32m   9441\u001b[0m         other,\n\u001b[1;32m   9442\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9449\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[1;32m   9450\u001b[0m     )\n\u001b[1;32m   9451\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[0;32m-> 9452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9455\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   9464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/generic.py:9581\u001b[0m, in \u001b[0;36mNDFrame._align_series\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m   9579\u001b[0m lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   9580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m join_index\u001b[38;5;241m.\u001b[39mequals(other\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m-> 9581\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mjoin_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_indexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   9583\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9586\u001b[0m     bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/indexes/base.py:228\u001b[0m, in \u001b[0;36m_maybe_return_indexers.<locals>.join\u001b[0;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(meth)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjoin\u001b[39m(\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    227\u001b[0m ):\n\u001b[0;32m--> 228\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_indexers:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m join_index\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/indexes/base.py:4653\u001b[0m, in \u001b[0;36mIndex.join\u001b[0;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[1;32m   4651\u001b[0m     this \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   4652\u001b[0m     other \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 4653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_indexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4655\u001b[0m _validate_join_method(how)\n\u001b[1;32m   4657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other\u001b[38;5;241m.\u001b[39mis_unique:\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/indexes/base.py:228\u001b[0m, in \u001b[0;36m_maybe_return_indexers.<locals>.join\u001b[0;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(meth)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjoin\u001b[39m(\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    227\u001b[0m ):\n\u001b[0;32m--> 228\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_indexers:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m join_index\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/indexes/base.py:4665\u001b[0m, in \u001b[0;36mIndex.join\u001b[0;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[1;32m   4660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_monotonic_increasing \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mis_monotonic_increasing:\n\u001b[1;32m   4661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interval_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   4662\u001b[0m         \u001b[38;5;66;03m# otherwise we will fall through to _join_via_get_indexer\u001b[39;00m\n\u001b[1;32m   4663\u001b[0m         \u001b[38;5;66;03m# GH#39133\u001b[39;00m\n\u001b[1;32m   4664\u001b[0m         \u001b[38;5;66;03m# go through object dtype for ea till engine is supported properly\u001b[39;00m\n\u001b[0;32m-> 4665\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_join_monotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4666\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_join_non_unique(other, how\u001b[38;5;241m=\u001b[39mhow)\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/indexes/base.py:5023\u001b[0m, in \u001b[0;36mIndex._join_monotonic\u001b[0;34m(self, other, how)\u001b[0m\n\u001b[1;32m   5021\u001b[0m         join_array, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_indexer(other)\n\u001b[1;32m   5022\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 5023\u001b[0m         join_array, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outer_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5025\u001b[0m     join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_joined_index(join_array, other)\n\u001b[1;32m   5027\u001b[0m lidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ensure_platform_int(lidx)\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/core/indexes/base.py:387\u001b[0m, in \u001b[0;36mIndex._outer_indexer\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    385\u001b[0m sv \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, sv)\n\u001b[1;32m    386\u001b[0m ov \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, ov)\n\u001b[0;32m--> 387\u001b[0m joined_ndarray, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mlibjoin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mouter_join_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m joined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_join_target(joined_ndarray)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m joined, lidx, ridx\n",
      "File \u001b[0;32m~/.pyenv/versions/bimpredict_new/lib/python3.10/site-packages/pandas/_libs/join.pyx:580\u001b[0m, in \u001b[0;36mpandas._libs.join.outer_join_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "def clean_id_columns(df_dict):\n",
    "    \"\"\"\n",
    "    Clean ID columns across all DataFrames by setting IDs to 0 when:\n",
    "    - The corresponding (u) column = 0 AND\n",
    "    - The (Ids) column is empty/NaN.\n",
    "    \"\"\"\n",
    "\n",
    "    COLUMN_PAIRS = [\n",
    "        ('Sols coupés (u)', 'Sols coupés (Ids)'),\n",
    "        ('Sols coupants (u)', 'Sols coupants (Ids)'),\n",
    "        ('Murs coupés (u)', 'Murs coupés (Ids)'),\n",
    "        ('Murs coupants (u)', 'Murs coupants (Ids)'),\n",
    "        ('Poutres coupés (u)', 'Poutres coupés (Ids)'),\n",
    "        ('Poutres coupants (u)', 'Poutres coupants (Ids)'),\n",
    "        ('Poteaux coupés (u)', 'Poteaux coupés (Ids)'),\n",
    "        ('Poteaux coupants (u)', 'Poteaux coupants (Ids)')\n",
    "    ]\n",
    "\n",
    "    for df_name, df in df_dict.items():\n",
    "        if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "            print(f\"⚠️ {df_name}: Empty or not a DataFrame\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'='*50}\\n🔍 Processing {df_name}\\n{'='*50}\")\n",
    "\n",
    "        for u_col, ids_col in COLUMN_PAIRS:\n",
    "            if u_col not in df.columns or ids_col not in df.columns:\n",
    "                print(f\"🚨 Skipping: {u_col} or {ids_col} not found in {df_name}\")\n",
    "                continue\n",
    "\n",
    "            # Convert `Ids` to string safely\n",
    "            df[ids_col] = df[ids_col].astype(str).replace(['nan', 'na', 'none', '', ' '], None)\n",
    "\n",
    "            # Apply cleaning condition\n",
    "            condition = (df[u_col] == 0) & (df[ids_col].isna())\n",
    "            df.loc[condition, ids_col] = \"0\"  # Set IDs to \"0\" when u = 0 and Ids is empty\n",
    "\n",
    "            # Show before/after for a few sample rows\n",
    "            print(f\"\\n🔹 Column Pair: {u_col} → {ids_col}\")\n",
    "            print(\"BEFORE:\", df.loc[condition.head(3).index, [u_col, ids_col]])\n",
    "            print(\"AFTER:\", df.loc[condition.head(3).index, [u_col, ids_col]])\n",
    "\n",
    "    return df_dict\n",
    "\n",
    "# Usage Example\n",
    "df_dict = {\n",
    "    'Murs': murs_df,\n",
    "    'Sols': sols_df,\n",
    "    'Poutres': poutres_df,\n",
    "    'Poteaux': poteaux_df\n",
    "}\n",
    "\n",
    "cleaned_dfs = clean_id_columns(df_dict)\n",
    "\n",
    "# Update DataFrames\n",
    "murs_df = cleaned_dfs['Murs']\n",
    "sols_df = cleaned_dfs['Sols']\n",
    "poutres_df = cleaned_dfs['Poutres']\n",
    "poteaux_df = cleaned_dfs['Poteaux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4282bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id 011EC_Lot 012EC_Ouvrage 013EC_Localisation 014EC_Mode Constructif  \\\n",
      "0  1632051       NaN           NaN                NaN                    NaN   \n",
      "1  1666165       NaN           NaN                NaN                    NaN   \n",
      "2  1702917       NaN           NaN                NaN                    NaN   \n",
      "3  1788246        GO        POUTRE          INTERIEUR         PREFA CHANTIER   \n",
      "4  1788248        GO        POUTRE          EXTERIEUR         PREFA CHANTIER   \n",
      "\n",
      "           Nom    AI    AS  Hauteur totale       Hauteur  \\\n",
      "0  Po(40x60ht) -4.32 -4.32    1.624301e-15  1.776357e-15   \n",
      "1  Po(40x60ht) -4.32 -4.32    1.624301e-15  1.776357e-15   \n",
      "2  Po(40x60ht) -4.32 -4.32    1.624301e-15  1.776357e-15   \n",
      "3  Po(20x60ht) -0.30  0.30    6.000000e-01  6.000000e-01   \n",
      "4  Po(20x60ht) -0.30  0.30    6.000000e-01  6.000000e-01   \n",
      "\n",
      "   Sols en intersection  Sols coupés (u) Sols coupés (Ids)  Sols coupants (u)  \\\n",
      "0                     0                0                []                  0   \n",
      "1                     0                0                []                  0   \n",
      "2                     0                0                []                  0   \n",
      "3                     0                0                []                  0   \n",
      "4                     0                0                []                  0   \n",
      "\n",
      "  Sols coupants (Ids)  Sol au-dessus  Sol en-dessous  Poteaux en intersection  \\\n",
      "0                  []           True            True                        0   \n",
      "1                  []           True            True                        0   \n",
      "2                  []           True            True                        0   \n",
      "3                  []          False           False                        0   \n",
      "4                  []          False           False                        0   \n",
      "\n",
      "   Poteaux coupés (u) Poteauc coupés (Ids)  Poteaux coupants (u)  \\\n",
      "0                   0                  NaN                     0   \n",
      "1                   0                  NaN                     0   \n",
      "2                   0                  NaN                     0   \n",
      "3                   0                  NaN                     0   \n",
      "4                   0                  NaN                     0   \n",
      "\n",
      "  Poteaux coupants (Ids)    Image  Etat de la jonction  Valeur de décalage Z  \\\n",
      "0                     []  <Aucun>                    0                   0.0   \n",
      "1                     []  <Aucun>                    0                   0.0   \n",
      "2                     []  <Aucun>                    0                   0.0   \n",
      "3                     []  <Aucun>                    1                   0.0   \n",
      "4                     []  <Aucun>                    0                   0.0   \n",
      "\n",
      "   Justification Z  Valeur de décalage Y  Justification Y  Justification YZ  \\\n",
      "0                0                     0                2                 0   \n",
      "1                0                     0                2                 0   \n",
      "2                0                     0                2                 0   \n",
      "3                0                     0                2                 0   \n",
      "4                0                     0                2                 0   \n",
      "\n",
      "  Catégorie  Type prédéfini d'IFC  Exporter au format IFC sous  \\\n",
      "0  Ossature                   NaN                          NaN   \n",
      "1  Ossature                   NaN                          NaN   \n",
      "2  Ossature                   NaN                          NaN   \n",
      "3  Ossature                   NaN                          NaN   \n",
      "4  Ossature                   NaN                          NaN   \n",
      "\n",
      "   Exporter au format IFC IfcGUID  A une association  \\\n",
      "0                       0     NaN                  1   \n",
      "1                       0     NaN                  1   \n",
      "2                       0     NaN                  1   \n",
      "3                       0     NaN                  1   \n",
      "4                       0     NaN                  1   \n",
      "\n",
      "  Enrobage d'armature - Face inférieure Enrobage d'armature - Face supérieure  \\\n",
      "0                                   NaN                                   NaN   \n",
      "1                                   NaN                                   NaN   \n",
      "2                                   NaN                                   NaN   \n",
      "3         Enrobage d'armature 1 <25 mm>                                   NaN   \n",
      "4         Enrobage d'armature 1 <25 mm>         Enrobage d'armature 1 <25 mm>   \n",
      "\n",
      "  Enrobage d'armature - Autres faces  Variantes    Volume Phase de démolition  \\\n",
      "0                                NaN         -1  0.000000            Aucun(e)   \n",
      "1                                NaN         -1  0.000000            Aucun(e)   \n",
      "2                                NaN         -1  0.000000            Aucun(e)   \n",
      "3      Enrobage d'armature 1 <25 mm>         -1  0.837985            Aucun(e)   \n",
      "4      Enrobage d'armature 1 <25 mm>         -1  0.763760            Aucun(e)   \n",
      "\n",
      "       Phase de création Commentaires Matériau structurel  ID hôte  Niveau  \\\n",
      "0  Nouvelle construction          NaN              C25/30       -1     NaN   \n",
      "1  Nouvelle construction          NaN              C25/30       -1     NaN   \n",
      "2  Nouvelle construction          NaN              C25/30       -1     NaN   \n",
      "3  Nouvelle construction          NaN              C25/30       -1     NaN   \n",
      "4  Nouvelle construction          NaN              C25/30       -1     NaN   \n",
      "\n",
      "                         Famille et type                   Famille  \\\n",
      "0  COG_POUTRE_RECTANGULAIRE: Po(40x60ht)  COG_POUTRE_RECTANGULAIRE   \n",
      "1  COG_POUTRE_RECTANGULAIRE: Po(40x60ht)  COG_POUTRE_RECTANGULAIRE   \n",
      "2  COG_POUTRE_RECTANGULAIRE: Po(40x60ht)  COG_POUTRE_RECTANGULAIRE   \n",
      "3  COG_POUTRE_RECTANGULAIRE: Po(20x60ht)  COG_POUTRE_RECTANGULAIRE   \n",
      "4  COG_POUTRE_RECTANGULAIRE: Po(20x60ht)  COG_POUTRE_RECTANGULAIRE   \n",
      "\n",
      "          Type  Nom de la famille  Nom du type  ID du type  \\\n",
      "0  Po(40x60ht)                NaN          NaN     1605340   \n",
      "1  Po(40x60ht)                NaN          NaN     1605340   \n",
      "2  Po(40x60ht)                NaN          NaN     1605340   \n",
      "3  Po(20x60ht)                NaN          NaN     1605332   \n",
      "4  Po(20x60ht)                NaN          NaN     1605332   \n",
      "\n",
      "   Elévation du niveau de référence  Elévation en haut  \\\n",
      "0                             -4.32              -4.32   \n",
      "1                              0.00              -4.32   \n",
      "2                              0.00              -4.32   \n",
      "3                              4.13               4.13   \n",
      "4                              4.13               4.13   \n",
      "\n",
      "   Rotation de la section  Orientation  Décalage du niveau d'arrivée  \\\n",
      "0                       0          0.0                  5.414336e-16   \n",
      "1                       0          0.0                  0.000000e+00   \n",
      "2                       0          0.0                  0.000000e+00   \n",
      "3                       0          0.0                  0.000000e+00   \n",
      "4                       0          0.0                 -1.082867e-15   \n",
      "\n",
      "   Décalage du niveau de départ  Elévation à la base  Longueur de coupe  \\\n",
      "0                  5.414336e-16                -4.32           0.000000   \n",
      "1                  0.000000e+00                -4.32           0.000000   \n",
      "2                  0.000000e+00                -4.32           0.000000   \n",
      "3                  0.000000e+00                 3.53           6.983211   \n",
      "4                 -1.082867e-15                 3.53           6.364663   \n",
      "\n",
      "  Niveau de référence  Utilisation structurelle  Plan de construction  \\\n",
      "0         Niveau SS-1                         6  Niveau : Niveau SS-1   \n",
      "1                 NaN                         6         <non associé>   \n",
      "2                 NaN                         6         <non associé>   \n",
      "3            Niveau 1                         6     Niveau : Niveau 1   \n",
      "4            Niveau 1                         6     Niveau : Niveau 1   \n",
      "\n",
      "   Longueur  Identifiant Nature_Ouvrage  Batiment  Perimetre coffrage  \\\n",
      "0  0.000000    1317234.0             BN       NaN                 1.6   \n",
      "1  0.000000          NaN             BN       NaN                 1.6   \n",
      "2  0.000000          NaN             BN       NaN                 1.6   \n",
      "3  7.083208    1261111.0            NaN       NaN                 1.4   \n",
      "4  6.364663    1261214.0            NaN       NaN                 1.4   \n",
      "\n",
      "     Vtotal  hauteur_section  largeur_section  NIVEAU_STRUCTURE Image du type  \\\n",
      "0  0.000000              0.6              0.4               NaN       <Aucun>   \n",
      "1  0.000000              0.6              0.4               NaN       <Aucun>   \n",
      "2  0.000000              0.6              0.4               NaN       <Aucun>   \n",
      "3  0.849985              0.6              0.2               NaN       <Aucun>   \n",
      "4  0.763760              0.6              0.2               NaN       <Aucun>   \n",
      "\n",
      "   Note d'identification  Type: Type prédéfini d'IFC  \\\n",
      "0                    NaN                         NaN   \n",
      "1                    NaN                         NaN   \n",
      "2                    NaN                         NaN   \n",
      "3                    NaN                         NaN   \n",
      "4                    NaN                         NaN   \n",
      "\n",
      "   Exporter le type au format IFC sous  Exporter le type au format IFC  \\\n",
      "0                                  NaN                               0   \n",
      "1                                  NaN                               0   \n",
      "2                                  NaN                               0   \n",
      "3                                  NaN                               0   \n",
      "4                                  NaN                               0   \n",
      "\n",
      "  Type IfcGUID  Modèle  Fabricant  Commentaires du type  URL  Description  \\\n",
      "0          NaN     NaN        NaN                   NaN  NaN          NaN   \n",
      "1          NaN     NaN        NaN                   NaN  NaN          NaN   \n",
      "2          NaN     NaN        NaN                   NaN  NaN          NaN   \n",
      "3          NaN     NaN        NaN                   NaN  NaN          NaN   \n",
      "4          NaN     NaN        NaN                   NaN  NaN          NaN   \n",
      "\n",
      "   Nom de code  Identifiant du nom de la coupe  Forme de coupe  \\\n",
      "0          NaN                             NaN               0   \n",
      "1          NaN                             NaN               0   \n",
      "2          NaN                             NaN               0   \n",
      "3          NaN                             NaN               0   \n",
      "4          NaN                             NaN               0   \n",
      "\n",
      "  Titre OmniClass Numéro OmniClass  Description de l'assemblage  \\\n",
      "0             NaN              NaN                          NaN   \n",
      "1             NaN              NaN                          NaN   \n",
      "2             NaN              NaN                          NaN   \n",
      "3             NaN              NaN                          NaN   \n",
      "4             NaN              NaN                          NaN   \n",
      "\n",
      "  Code d'assemblage  Marque de type  Protection contre l'incendie  Coût    h  \\\n",
      "0               NaN             NaN                           NaN     0  0.6   \n",
      "1               NaN             NaN                           NaN     0  0.6   \n",
      "2               NaN             NaN                           NaN     0  0.6   \n",
      "3               NaN             NaN                           NaN     0  0.6   \n",
      "4               NaN             NaN                           NaN     0  0.6   \n",
      "\n",
      "     b Type Ossature  Type d'attachement de fin  Type d'attachement de début  \\\n",
      "0  0.4            Po                        NaN                          NaN   \n",
      "1  0.4            Po                        NaN                          NaN   \n",
      "2  0.4            Po                        NaN                          NaN   \n",
      "3  0.2            Po                        NaN                          NaN   \n",
      "4  0.2            Po                        NaN                          NaN   \n",
      "\n",
      "   LG_DECAISSE  ht-decaisse  \n",
      "0          NaN          NaN  \n",
      "1          NaN          NaN  \n",
      "2          NaN          NaN  \n",
      "3          NaN          NaN  \n",
      "4          NaN          NaN  \n",
      "Id                               int64\n",
      "011EC_Lot                       object\n",
      "012EC_Ouvrage                   object\n",
      "013EC_Localisation              object\n",
      "014EC_Mode Constructif          object\n",
      "                                ...   \n",
      "Type Ossature                   object\n",
      "Type d'attachement de fin      float64\n",
      "Type d'attachement de début    float64\n",
      "LG_DECAISSE                    float64\n",
      "ht-decaisse                    float64\n",
      "Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(poutres_df.head())\n",
    "print(poutres_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relationship_features(main_df, related_df, relation_config, prefix):\n",
    "    \"\"\"\n",
    "    Robust relationship feature creation with:\n",
    "    - Better column name handling\n",
    "    - NaN/empty value protection\n",
    "    - Clear validation\n",
    "    \"\"\"\n",
    "    for relation_col, feature_cols in relation_config.items():\n",
    "        # 1. Find matching column (case insensitive, handles typos)\n",
    "        matching_cols = [col for col in main_df.columns\n",
    "                        if relation_col.lower() in col.lower()]\n",
    "\n",
    "        if not matching_cols:\n",
    "            print(f\"⚠️ No column matching '{relation_col}' found in DataFrame\")\n",
    "            continue\n",
    "\n",
    "        actual_col = matching_cols[0]\n",
    "        print(f\"🔧 Processing {actual_col} (matched from {relation_col})\")\n",
    "\n",
    "        # 2. Clean and explode relationship IDs\n",
    "        try:\n",
    "            # Convert to string and clean\n",
    "            main_df[actual_col] = main_df[actual_col].astype(str)\n",
    "            main_df[actual_col] = (main_df[actual_col]\n",
    "                                  .str.replace(r'[\\[\\]]', '', regex=True)\n",
    "                                  .replace(['nan', 'None', 'NaN', ''], '0'))\n",
    "\n",
    "            # Explode and convert to integers\n",
    "            exploded = main_df[[actual_col]].explode(actual_col)\n",
    "            exploded[actual_col] = pd.to_numeric(exploded[actual_col], errors='coerce')\n",
    "            exploded = exploded.dropna()\n",
    "\n",
    "            if exploded.empty:\n",
    "                print(f\"⚠️ No valid relationships in {actual_col}\")\n",
    "                continue\n",
    "\n",
    "            # 3. Merge with related features\n",
    "            for feature in feature_cols:\n",
    "                if feature not in related_df.columns:\n",
    "                    print(f\"⚠️ Feature '{feature}' not in related DataFrame\")\n",
    "                    continue\n",
    "\n",
    "                # Perform the merge\n",
    "                merged = exploded.merge(\n",
    "                    related_df[[feature]],\n",
    "                    left_on=actual_col,\n",
    "                    right_index=True,\n",
    "                    how='left'\n",
    "                )\n",
    "\n",
    "                # Aggregate back to original\n",
    "                new_col = f\"{prefix}_{feature}\"\n",
    "                if np.issubdtype(merged[feature].dtype, np.number):\n",
    "                    main_df[new_col] = merged.groupby(merged.index)[feature].mean()\n",
    "                else:\n",
    "                    main_df[new_col] = merged.groupby(merged.index)[feature].agg(\n",
    "                        lambda x: x.mode()[0] if not x.empty else np.nan\n",
    "                    )\n",
    "\n",
    "                print(f\"✅ Created {new_col}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {actual_col}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82837828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Murs relationships:\n",
      "🔧 Processing Sols coupés (Ids) (matched from Sols coupés (Ids))\n",
      "⚠️ Feature 'Hauteur' not in related DataFrame\n",
      "✅ Created sol_Epaisseur\n",
      "✅ Created sol_Volume\n",
      "✅ Created sol_Surface\n",
      "🔧 Processing Sols coupants (Ids) (matched from Sols coupants (Ids))\n",
      "⚠️ Feature 'Hauteur' not in related DataFrame\n",
      "✅ Created sol_Epaisseur\n",
      "✅ Created sol_Volume\n",
      "✅ Created sol_Surface\n",
      "\n",
      "Created features in Murs:\n",
      "['sol_Epaisseur', 'sol_Volume', 'sol_Surface']\n"
     ]
    }
   ],
   "source": [
    "# Define your relationship configs (corrected for typos)\n",
    "mur_relations = {\n",
    "    'Sols coupés (Ids)': ['Hauteur', 'Epaisseur', 'Volume', 'Surface'],\n",
    "    'Sols coupants (Ids)': ['Hauteur', 'Epaisseur', 'Volume', 'Surface']\n",
    "}\n",
    "\n",
    "# Process with corrected function\n",
    "print(\"\\nProcessing Murs relationships:\")\n",
    "murs_df = create_relationship_features(murs_df, sols_df, mur_relations, 'sol')\n",
    "\n",
    "# Verify\n",
    "print(\"\\nCreated features in Murs:\")\n",
    "print([col for col in murs_df.columns if col.startswith('sol_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2be75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_validation():\n",
    "    \"\"\"Run complete validation suite with robust checks\"\"\"\n",
    "    dfs = {\n",
    "        'Murs': murs_df,\n",
    "        'Sols': sols_df,\n",
    "        'Poutres': poutres_df,\n",
    "        'Poteaux': poteaux_df\n",
    "    }\n",
    "\n",
    "    # 1. Basic DataFrame verification\n",
    "    print(\"=\"*50 + \"\\nBasic DataFrame Verification\\n\" + \"=\"*50)\n",
    "    for name, df in dfs.items():\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            print(f\"\\n❌ {name}: Not a DataFrame\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n🔍 {name} DataFrame:\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "        # Check relationship columns\n",
    "        rel_cols = [c for c in df.columns if 'coup' in c.lower()]\n",
    "        print(f\"\\nRelationship columns ({len(rel_cols)}):\")\n",
    "        print(rel_cols)\n",
    "\n",
    "        # Check created features\n",
    "        created_features = [c for c in df.columns if any(x in c for x in ['sol_', 'mur_', 'poutre_', 'poteau_'])]\n",
    "        print(f\"\\nCreated features ({len(created_features)}):\")\n",
    "        if created_features:\n",
    "            print(df[created_features].head(2))\n",
    "        else:\n",
    "            print(\"No relationship features created\")\n",
    "\n",
    "    # 2. Detailed relationship validation\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\nDetailed Relationship Validation\\n\" + \"=\"*50)\n",
    "\n",
    "    def safe_validate(main_df, related_df, relation_col, prefix):\n",
    "        \"\"\"Validate relationships with error handling\"\"\"\n",
    "        try:\n",
    "            if relation_col not in main_df.columns:\n",
    "                print(f\"❌ Missing relation column: {relation_col}\")\n",
    "                return\n",
    "\n",
    "            created_cols = [f\"{prefix}_{f}\" for f in ['Hauteur', 'Epaisseur', 'Volume', 'Surface']\n",
    "                          if f\"{prefix}_{f}\" in main_df.columns]\n",
    "\n",
    "            if not created_cols:\n",
    "                print(f\"⚠️ No features created for {relation_col}\")\n",
    "                return\n",
    "\n",
    "            print(f\"\\n✅ Validating {relation_col}:\")\n",
    "            print(f\"Created {len(created_cols)} features\")\n",
    "            print(\"Sample values:\")\n",
    "            print(main_df[created_cols].head(2))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Validation failed for {relation_col}: {str(e)}\")\n",
    "\n",
    "    # Validate each relationship type\n",
    "    if isinstance(murs_df, pd.DataFrame):\n",
    "        safe_validate(murs_df, sols_df, 'Sols coupés (Ids)', 'sol')\n",
    "        safe_validate(murs_df, sols_df, 'Sols coupants (Ids)', 'sol')\n",
    "\n",
    "    if isinstance(sols_df, pd.DataFrame):\n",
    "        safe_validate(sols_df, murs_df, 'Murs coupés (Ids)', 'murs')\n",
    "        safe_validate(sols_df, poutres_df, 'Poutres coupés (Ids)', 'poutres')\n",
    "\n",
    "    if isinstance(poutres_df, pd.DataFrame):\n",
    "        safe_validate(poutres_df, sols_df, 'Sols coupés (Ids)', 'sol')\n",
    "        safe_validate(poutres_df, poteaux_df, 'Poteaux coupés (Ids)', 'poteaux')\n",
    "\n",
    "    if isinstance(poteaux_df, pd.DataFrame):\n",
    "        safe_validate(poteaux_df, sols_df, 'Sols coupés (Ids)', 'sol')\n",
    "        safe_validate(poteaux_df, poutres_df, 'Poutres coupés (Ids)', 'poutres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03686e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Basic DataFrame Verification\n",
      "==================================================\n",
      "\n",
      "🔍 Murs DataFrame:\n",
      "Shape: (312, 96)\n",
      "Columns: ['Id', '011EC_Lot', '012EC_Ouvrage', '013EC_Localisation', '014EC_Mode Constructif', 'Nom', 'Hauteur', 'Epaisseur', 'AI', 'AS', 'Sols en intersection', 'Sols coupés (u)', 'Sols coupés (Ids)', 'Sols coupants (u)', 'Sols coupants (Ids)', 'Sol au-dessus', 'Sol en-dessous', 'Fenêtres', 'Portes', 'Ouvertures', 'Murs imbriqués', 'Mur multicouche', 'Mur empilé', 'Profil modifié', 'Image', 'Catégorie', 'Section', \"Type prédéfini d'IFC\", 'Exporter au format IFC sous', 'Exporter au format IFC', 'IfcGUID', 'A une association', \"Enrobage d'armature - Autres faces\", \"Enrobage d'armature - Face intérieure\", \"Enrobage d'armature - Face extérieure\", 'Variantes', 'Extension inférieure', 'Extension supérieure', 'Volume', 'Surface', 'Phase de démolition', 'Phase de création', 'Commentaires', 'Longueur', 'Famille et type', 'Famille', 'Type', 'Nom de la famille', 'Nom du type', 'ID du type', 'Lié au volume', 'Structure', 'Identifiant', 'Ligne de justification', 'Utilisation structurelle', 'Partie inférieure attachée', 'Partie supérieure attachée', 'Décalage supérieur', 'Décalage inférieur', 'Contrainte inférieure', 'Hauteur non contrainte', 'Contrainte supérieure', 'Limite de pièce', 'Nature_Ouvrage', 'Batiment', 'Mur armé', 'Affichage poteau', 'NIVEAU_STRUCTURE', 'Image du type', \"Note d'identification\", \"Type: Type prédéfini d'IFC\", 'Exporter le type au format IFC sous', 'Exporter le type au format IFC', 'Type IfcGUID', 'Modèle', 'Fabricant', 'Commentaires du type', 'URL', 'Description', 'Matériau structurel', 'Rugosité', \"Coefficient d'absorbance\", 'Masse thermique', 'Résistance thermique (R)', 'Coefficient de transfert thermique (U)', \"Description de l'assemblage\", \"Code d'assemblage\", 'Retournement aux insertions', 'Retournement aux extrémités', 'Couleur vue détail faible', 'Motif vue détail faible', 'Marque de type', \"Protection contre l'incendie\", 'Coût', 'Fonction', 'Largeur']\n",
      "\n",
      "Relationship columns (4):\n",
      "['Sols coupés (u)', 'Sols coupés (Ids)', 'Sols coupants (u)', 'Sols coupants (Ids)']\n",
      "\n",
      "Created features (0):\n",
      "No relationship features created\n",
      "\n",
      "🔍 Sols DataFrame:\n",
      "Shape: (107, 94)\n",
      "Columns: ['Id', '011EC_Lot', '012EC_Ouvrage', '013EC_Localisation', '014EC_Mode Constructif', 'Nom', 'Murs en intersection', 'Murs coupés (u)', 'Murs coupés (Ids)', 'Murs coupants (u)', 'Murs coupants (Ids)', 'Poutres en intersection', 'Poutres coupés (u)', 'Poutres coupés (Ids)', 'Poutres coupants (u)', 'Poutres coupants (Ids)', 'Poteaux en intersection', 'Poteaux coupés (u)', 'Poteaux coupés (Ids)', 'Poteaux coupants (u)', 'Poteaux coupants (Ids)', 'Ouvertures', 'Sol multicouche', 'Profil modifié', 'Image', 'Catégorie', \"Type prédéfini d'IFC\", 'Exporter au format IFC sous', 'Exporter au format IFC', 'IfcGUID', 'A une association', \"Enrobage d'armature - Face inférieure\", \"Enrobage d'armature - Face supérieure\", \"Enrobage d'armature - Autres faces\", 'Variantes', 'Volume', 'Surface', 'Phase de démolition', 'Phase de création', 'Commentaires', 'Inclinaison', 'Niveau', 'Famille et type', 'Famille', 'Type', 'Nom de la famille', 'Nom du type', 'ID du type', 'Structure', 'Périmètre', 'Décalage par rapport au niveau', 'Epaisseur', 'Lié au volume', \"Etude de l'élévation à la base\", \"Etude de l'élévation en haut\", 'Epaisseur du porteur', 'Elévation au niveau du noyau inférieur', 'Elévation au niveau du noyau supérieur', 'Elévation en haut', 'Elévation à la base', 'Identifiant', 'Limite de pièce', 'Nature_Ouvrage', 'Batiment', 'Niveau fini', 'Niveau Brut', 'NIVEAU_STRUCTURE', 'Image du type', \"Note d'identification\", \"Type: Type prédéfini d'IFC\", 'Exporter le type au format IFC sous', 'Exporter le type au format IFC', 'Type IfcGUID', 'Modèle', 'Fabricant', 'Commentaires du type', 'URL', 'Description', 'Matériau structurel', 'Rugosité', \"Coefficient d'absorbance\", 'Masse thermique', 'Résistance thermique (R)', 'Coefficient de transfert thermique (U)', \"Description de l'assemblage\", \"Code d'assemblage\", 'Couleur vue détail faible', 'Motif vue détail faible', 'Epaisseur par défaut', 'Marque de type', 'Coût', 'Fonction', 'épaisseur', 'Condition de bord incurvé']\n",
      "\n",
      "Relationship columns (12):\n",
      "['Murs coupés (u)', 'Murs coupés (Ids)', 'Murs coupants (u)', 'Murs coupants (Ids)', 'Poutres coupés (u)', 'Poutres coupés (Ids)', 'Poutres coupants (u)', 'Poutres coupants (Ids)', 'Poteaux coupés (u)', 'Poteaux coupés (Ids)', 'Poteaux coupants (u)', 'Poteaux coupants (Ids)']\n",
      "\n",
      "Created features (0):\n",
      "No relationship features created\n",
      "\n",
      "🔍 Poutres DataFrame:\n",
      "Shape: (246, 100)\n",
      "Columns: ['Id', '011EC_Lot', '012EC_Ouvrage', '013EC_Localisation', '014EC_Mode Constructif', 'Nom', 'AI', 'AS', 'Hauteur totale', 'Hauteur', 'Sols en intersection', 'Sols coupés (u)', 'Sols coupés (Ids)', 'Sols coupants (u)', 'Sols coupants (Ids)', 'Sol au-dessus', 'Sol en-dessous', 'Poteaux en intersection', 'Poteaux coupés (u)', 'Poteauc coupés (Ids)', 'Poteaux coupants (u)', 'Poteaux coupants (Ids)', 'Image', 'Etat de la jonction', 'Valeur de décalage Z', 'Justification Z', 'Valeur de décalage Y', 'Justification Y', 'Justification YZ', 'Catégorie', \"Type prédéfini d'IFC\", 'Exporter au format IFC sous', 'Exporter au format IFC', 'IfcGUID', 'A une association', \"Enrobage d'armature - Face inférieure\", \"Enrobage d'armature - Face supérieure\", \"Enrobage d'armature - Autres faces\", 'Variantes', 'Volume', 'Phase de démolition', 'Phase de création', 'Commentaires', 'Matériau structurel', 'ID hôte', 'Niveau', 'Famille et type', 'Famille', 'Type', 'Nom de la famille', 'Nom du type', 'ID du type', 'Elévation du niveau de référence', 'Elévation en haut', 'Rotation de la section', 'Orientation', \"Décalage du niveau d'arrivée\", 'Décalage du niveau de départ', 'Elévation à la base', 'Longueur de coupe', 'Niveau de référence', 'Utilisation structurelle', 'Plan de construction', 'Longueur', 'Identifiant', 'Nature_Ouvrage', 'Batiment', 'Perimetre coffrage', 'Vtotal', 'hauteur_section', 'largeur_section', 'NIVEAU_STRUCTURE', 'Image du type', \"Note d'identification\", \"Type: Type prédéfini d'IFC\", 'Exporter le type au format IFC sous', 'Exporter le type au format IFC', 'Type IfcGUID', 'Modèle', 'Fabricant', 'Commentaires du type', 'URL', 'Description', 'Nom de code', 'Identifiant du nom de la coupe', 'Forme de coupe', 'Titre OmniClass', 'Numéro OmniClass', \"Description de l'assemblage\", \"Code d'assemblage\", 'Marque de type', \"Protection contre l'incendie\", 'Coût', 'h', 'b', 'Type Ossature', \"Type d'attachement de fin\", \"Type d'attachement de début\", 'LG_DECAISSE', 'ht-decaisse']\n",
      "\n",
      "Relationship columns (11):\n",
      "['Sols coupés (u)', 'Sols coupés (Ids)', 'Sols coupants (u)', 'Sols coupants (Ids)', 'Poteaux coupés (u)', 'Poteauc coupés (Ids)', 'Poteaux coupants (u)', 'Poteaux coupants (Ids)', 'Longueur de coupe', 'Identifiant du nom de la coupe', 'Forme de coupe']\n",
      "\n",
      "Created features (0):\n",
      "No relationship features created\n",
      "\n",
      "🔍 Poteaux DataFrame:\n",
      "Shape: (68, 87)\n",
      "Columns: ['Id', '011EC_Lot', '012EC_Ouvrage', '013EC_Localisation', '014EC_Mode Constructif', 'Nom', 'AI', 'AS', 'Hauteur', 'Longueur', 'Partie inférieure attachée', 'Partie supérieure attachée', 'Sols en intersection', 'Sols coupés (u)', 'Sols coupés (Ids)', 'Sols coupants (u)', 'Sols coupants (Ids)', 'Poutres en intersection', 'Poutres coupés (u)', 'Poutres coupés (Ids)', 'Poutres coupants (u)', 'Poutres coupants (Ids)', 'Image', 'Style de poteau', 'Catégorie', \"Type prédéfini d'IFC\", 'Exporter au format IFC sous', 'Exporter au format IFC', 'IfcGUID', 'A une association', \"Enrobage d'armature - Face inférieure\", \"Enrobage d'armature - Face supérieure\", \"Enrobage d'armature - Autres faces\", 'Variantes', 'Volume', 'Phase de démolition', 'Phase de création', 'Commentaires', 'Matériau structurel', \"Marque d'emplacement du poteau\", 'ID hôte', 'Décalage supérieur', 'Décalage inférieur', 'Niveau supérieur', 'Niveau de base', 'Niveau', 'Famille et type', 'Famille', 'Type', 'Nom de la famille', 'Nom du type', 'ID du type', 'Se déplace avec les quadrillages', 'Identifiant', 'Limite de pièce', 'Batiment', 'NIVEAU_STRUCTURE', 'Image du type', \"Note d'identification\", \"Type: Type prédéfini d'IFC\", 'Exporter le type au format IFC sous', 'Exporter le type au format IFC', 'Type IfcGUID', 'Modèle', 'Fabricant', 'Commentaires du type', 'URL', 'Description', 'Nom de code', 'Identifiant du nom de la coupe', 'Forme de coupe', 'Titre OmniClass', 'Numéro OmniClass', \"Description de l'assemblage\", \"Code d'assemblage\", 'Marque de type', 'Coût', 'Nature_Ouvrage', 'Diamètre poteau', 'h', 'b', 'hauteur_section', 'largeur_section', \"Décalage de l'attachement à la base\", \"Justification de l'attachement en bas\", \"Décalage de l'attachement en haut\", \"Justification de l'attachement en haut\"]\n",
      "\n",
      "Relationship columns (10):\n",
      "['Sols coupés (u)', 'Sols coupés (Ids)', 'Sols coupants (u)', 'Sols coupants (Ids)', 'Poutres coupés (u)', 'Poutres coupés (Ids)', 'Poutres coupants (u)', 'Poutres coupants (Ids)', 'Identifiant du nom de la coupe', 'Forme de coupe']\n",
      "\n",
      "Created features (0):\n",
      "No relationship features created\n",
      "\n",
      "==================================================\n",
      "Detailed Relationship Validation\n",
      "==================================================\n",
      "⚠️ No features created for Sols coupés (Ids)\n",
      "⚠️ No features created for Sols coupants (Ids)\n",
      "⚠️ No features created for Murs coupés (Ids)\n",
      "⚠️ No features created for Poutres coupés (Ids)\n",
      "⚠️ No features created for Sols coupés (Ids)\n",
      "❌ Missing relation column: Poteaux coupés (Ids)\n",
      "⚠️ No features created for Sols coupés (Ids)\n",
      "⚠️ No features created for Poutres coupés (Ids)\n"
     ]
    }
   ],
   "source": [
    "full_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f4d6b",
   "metadata": {},
   "source": [
    "## Part 3: Feature Engineering and Target Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd559d47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Feature selection for Murs DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# We'll exclude the target columns and ID columns from features\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m excluded_features \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_columns\u001b[49m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSols coupés (Ids)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSols coupants (Ids)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m features \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m mur_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m excluded_features]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Separate features and targets\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_columns' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature selection for Murs DataFrame\n",
    "# We'll exclude the target columns and ID columns from features\n",
    "excluded_features = target_columns + ['Id', 'Sols coupés (Ids)', 'Sols coupants (Ids)']\n",
    "features = [col for col in mur_df.columns if col not in excluded_features]\n",
    "\n",
    "# Separate features and targets\n",
    "X = mur_df[features]\n",
    "y = mur_df[target_columns]\n",
    "\n",
    "# Handle categorical features (text with special French characters)\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numeric_cols = X.select_dtypes(include=np.number).columns\n",
    "\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Numeric transformer\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical transformer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# For multi-label classification, we'll use separate models for each target\n",
    "# Or we can combine them into a single target (less recommended due to different natures)\n",
    "# Here we'll proceed with separate models\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "# For numeric features\n",
    "numeric_feature_names = numeric_cols.tolist()\n",
    "\n",
    "# For categorical features\n",
    "if len(categorical_cols) > 0:\n",
    "    ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    categorical_feature_names = ohe.get_feature_names_out(categorical_cols).tolist()\n",
    "    all_feature_names = numeric_feature_names + categorical_feature_names\n",
    "else:\n",
    "    all_feature_names = numeric_feature_names\n",
    "\n",
    "print(f\"Total features after preprocessing: {len(all_feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa95fecb",
   "metadata": {},
   "source": [
    "## Part 4: Exploratory Data Analysis and Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for each target variable\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# For numeric features only (correlation requires numeric data)\n",
    "numeric_df = X[numeric_cols]\n",
    "\n",
    "# Add targets to the numeric_df for correlation\n",
    "for target in target_columns:\n",
    "    if target in mur_df.columns:\n",
    "        # Encode target for correlation\n",
    "        le = LabelEncoder()\n",
    "        encoded_target = le.fit_transform(mur_df[target])\n",
    "        numeric_df[target] = encoded_target\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# Plot heatmap for each target\n",
    "for i, target in enumerate(target_columns, 1):\n",
    "    if target in numeric_df.columns:\n",
    "        plt.subplot(2, 2, i)\n",
    "        target_corr = corr_matrix[target].sort_values(ascending=False)\n",
    "        sns.barplot(x=target_corr.values[1:11], y=target_corr.index[1:11])\n",
    "        plt.title(f'Top 10 Features Correlated with {target}')\n",
    "        plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Analyze distribution of target variables\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, target in enumerate(target_columns, 1):\n",
    "    if target in mur_df.columns:\n",
    "        plt.subplot(2, 2, i)\n",
    "        sns.countplot(y=mur_df[target], order=mur_df[target].value_counts().index)\n",
    "        plt.title(f'Distribution of {target}')\n",
    "        plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# SHAP analysis for feature importance (sample for one target)\n",
    "if '012EC_Ouvrage' in mur_df.columns:\n",
    "    # Sample a subset for faster SHAP computation\n",
    "    X_sample = X_processed[:1000] if X_processed.shape[0] > 1000 else X_processed\n",
    "\n",
    "    # Train a model for this target\n",
    "    y_target = mur_df['012EC_Ouvrage']\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_target)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sample, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Compute SHAP values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Plot summary\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_test, feature_names=all_feature_names, class_names=le.classes_)\n",
    "    plt.title('SHAP Summary for 012EC_Ouvrage Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a9247",
   "metadata": {},
   "source": [
    "## Part 5: Model Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate models for a target variable\n",
    "def train_evaluate_models(X, y, target_name, models):\n",
    "    \"\"\"\n",
    "    Train and evaluate multiple models for a target variable\n",
    "\n",
    "    Args:\n",
    "        X: Features (processed)\n",
    "        y: Target variable\n",
    "        target_name: Name of the target variable\n",
    "        models: Dictionary of models to evaluate\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of model performances\n",
    "    \"\"\"\n",
    "    # Encode target if categorical\n",
    "    if y.dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name} for {target_name}...\")\n",
    "\n",
    "        try:\n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Evaluate\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "            # Store results\n",
    "            results[model_name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': report['weighted avg']['precision'],\n",
    "                'recall': report['weighted avg']['recall'],\n",
    "                'f1': report['weighted avg']['f1-score']\n",
    "            }\n",
    "\n",
    "            print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            # Save model based on type\n",
    "            if hasattr(model, 'layers'):  # Keras model\n",
    "                model_path = f\"dlmodels/{target_name}_{model_name}.h5\"\n",
    "                model.save(model_path)\n",
    "            elif 'boost' in model_name.lower() or 'forest' in model_name.lower():\n",
    "                model_path = f\"mlmodels/{target_name}_{model_name}.pkl\"\n",
    "                import joblib\n",
    "                joblib.dump(model, model_path)\n",
    "            else:\n",
    "                model_path = f\"simplemodels/{target_name}_{model_name}.pkl\"\n",
    "                import joblib\n",
    "                joblib.dump(model, model_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {model_name}: {e}\")\n",
    "            results[model_name] = None\n",
    "\n",
    "    return results\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Add a simple neural network\n",
    "def create_nn_model(input_dim, output_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# For each target variable, train and evaluate models\n",
    "all_results = {}\n",
    "\n",
    "for target in target_columns:\n",
    "    if target in mur_df.columns:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training models for target: {target}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        y_target = mur_df[target]\n",
    "\n",
    "        # Skip if all values are the same\n",
    "        if len(y_target.unique()) == 1:\n",
    "            print(f\"Skipping {target} - only one class present.\")\n",
    "            continue\n",
    "\n",
    "        # Add neural network to models\n",
    "        output_dim = len(y_target.unique())\n",
    "        nn_model = create_nn_model(X_processed.shape[1], output_dim)\n",
    "        models['NeuralNetwork'] = nn_model\n",
    "\n",
    "        # Train and evaluate\n",
    "        results = train_evaluate_models(X_processed, y_target, target, models)\n",
    "        all_results[target] = results\n",
    "\n",
    "        # Remove NN for next target (to recreate with correct output dim)\n",
    "        del models['NeuralNetwork']\n",
    "\n",
    "        # Plot model comparison\n",
    "        if results:\n",
    "            df_results = pd.DataFrame(results).T\n",
    "            df_results['accuracy'].plot(kind='bar', title=f'Model Accuracy for {target}')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Display all results\n",
    "for target, results in all_results.items():\n",
    "    print(f\"\\nResults for {target}:\")\n",
    "    if results:\n",
    "        display(pd.DataFrame(results).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6b79ed",
   "metadata": {},
   "source": [
    "## Part 6: Model Interpretation and Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490629b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpret best model for each target\n",
    "def interpret_best_model(target, results, X_processed, y_target):\n",
    "    \"\"\"\n",
    "    Interpret the best model for a target using SHAP\n",
    "\n",
    "    Args:\n",
    "        target: Target variable name\n",
    "        results: Dictionary of model results\n",
    "        X_processed: Processed features\n",
    "        y_target: Target values\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        return\n",
    "\n",
    "    # Find best model by accuracy\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    best_model_name = df_results['accuracy'].idxmax()\n",
    "    best_model_accuracy = df_results.loc[best_model_name, 'accuracy']\n",
    "\n",
    "    print(f\"\\nInterpreting best model for {target}: {best_model_name} (Accuracy: {best_model_accuracy:.4f})\")\n",
    "\n",
    "    # Load the best model\n",
    "    if 'NeuralNetwork' in best_model_name:\n",
    "        model_path = f\"dlmodels/{target}_{best_model_name}.h5\"\n",
    "        best_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "        # For neural networks, we'll use a different explainer\n",
    "        # Sample data for faster computation\n",
    "        X_sample = X_processed[:100] if X_processed.shape[0] > 100 else X_processed\n",
    "\n",
    "        # Create a SHAP explainer\n",
    "        explainer = shap.DeepExplainer(best_model, X_sample)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "        # Plot summary\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values, X_sample, feature_names=all_feature_names)\n",
    "        plt.title(f'SHAP Summary for {target} ({best_model_name})')\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        if 'boost' in best_model_name.lower() or 'forest' in best_model_name.lower():\n",
    "            model_path = f\"mlmodels/{target}_{best_model_name}.pkl\"\n",
    "        else:\n",
    "            model_path = f\"simplemodels/{target}_{best_model_name}.pkl\"\n",
    "\n",
    "        import joblib\n",
    "        best_model = joblib.load(model_path)\n",
    "\n",
    "        # Create SHAP explainer\n",
    "        X_sample = X_processed[:100] if X_processed.shape[0] > 100 else X_processed\n",
    "\n",
    "        if hasattr(best_model, 'predict_proba'):\n",
    "            explainer = shap.TreeExplainer(best_model)\n",
    "            shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "            # Plot summary\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values, X_sample, feature_names=all_feature_names)\n",
    "            plt.title(f'SHAP Summary for {target} ({best_model_name})')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Cannot create SHAP explainer for {best_model_name}\")\n",
    "\n",
    "# Interpret best models for each target\n",
    "for target, results in all_results.items():\n",
    "    y_target = mur_df[target]\n",
    "    interpret_best_model(target, results, X_processed, y_target)\n",
    "\n",
    "# Final recommendations\n",
    "print(\"\\nFinal Recommendations:\")\n",
    "print(\"1. The best performing models have been saved in their respective folders (simplemodels/, mlmodels/, dlmodels/)\")\n",
    "print(\"2. SHAP analysis has been provided for model interpretability\")\n",
    "print(\"3. Consider feature engineering based on the correlation and SHAP analysis\")\n",
    "print(\"4. For deployment, use the best model for each target variable\")\n",
    "print(\"5. Monitor model performance over time as new data becomes available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0590ec",
   "metadata": {},
   "source": [
    "## Part 7: Learning Curves and Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c2ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot learning curves\n",
    "def plot_learning_curve(model, X, y, model_name, target_name):\n",
    "    \"\"\"\n",
    "    Plot learning curves for a model\n",
    "\n",
    "    Args:\n",
    "        model: The model to evaluate\n",
    "        X: Features\n",
    "        y: Target\n",
    "        model_name: Name of the model\n",
    "        target_name: Name of the target variable\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import learning_curve\n",
    "\n",
    "    # If y is categorical, encode it\n",
    "    if y.dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "\n",
    "    # Create CV training and test scores for various training set sizes\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=5, scoring='accuracy',\n",
    "        train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "    # Calculate mean and standard deviation for training set scores\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "    # Calculate mean and standard deviation for test set scores\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')\n",
    "    plt.plot(train_sizes, test_mean, 'o-', color='green', label='Cross-validation score')\n",
    "\n",
    "    # Draw bands\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='green')\n",
    "\n",
    "    # Create plot\n",
    "    plt.title(f'Learning Curve for {model_name} ({target_name})')\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curves for best models\n",
    "for target, results in all_results.items():\n",
    "    if results:\n",
    "        # Find best model by accuracy\n",
    "        df_results = pd.DataFrame(results).T\n",
    "        best_model_name = df_results['accuracy'].idxmax()\n",
    "\n",
    "        # Load the best model\n",
    "        if 'NeuralNetwork' in best_model_name:\n",
    "            model_path = f\"dlmodels/{target}_{best_model_name}.h5\"\n",
    "            best_model = tf.keras.models.load_model(model_path)\n",
    "        elif 'boost' in best_model_name.lower() or 'forest' in best_model_name.lower():\n",
    "            model_path = f\"mlmodels/{target}_{best_model_name}.pkl\"\n",
    "            import joblib\n",
    "            best_model = joblib.load(model_path)\n",
    "        else:\n",
    "            model_path = f\"simplemodels/{target}_{best_model_name}.pkl\"\n",
    "            import joblib\n",
    "            best_model = joblib.load(model_path)\n",
    "\n",
    "        # Get target data\n",
    "        y_target = mur_df[target]\n",
    "\n",
    "        # Plot learning curve\n",
    "        plot_learning_curve(best_model, X_processed, y_target, best_model_name, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad02ea",
   "metadata": {},
   "source": [
    "Explanation and Next Steps\n",
    "This comprehensive solution provides:\n",
    "\n",
    "Data Loading and Preprocessing: Handles the complex relationships between different BIM elements (Murs, Sols, Poutres, Poteaux) and processes the French text data with special characters.\n",
    "\n",
    "Feature Engineering: Creates relationship features between different BIM elements based on their intersections and cuts.\n",
    "\n",
    "Exploratory Data Analysis: Includes correlation analysis and target distribution visualization.\n",
    "\n",
    "Model Training: Evaluates multiple machine learning models (Logistic Regression, Random Forest, SVM, XGBoost, LightGBM) and a neural network for each target variable.\n",
    "\n",
    "Model Interpretation: Uses SHAP values to explain model predictions and identify important features.\n",
    "\n",
    "Model Saving: Saves the best models in appropriate folders based on their complexity (simplemodels/, mlmodels/, dlmodels/).\n",
    "\n",
    "Learning Curves: Visualizes model performance with increasing training data size.\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "Deploy the best models for each target variable in your BIM system.\n",
    "\n",
    "Set up monitoring to track model performance over time.\n",
    "\n",
    "Consider implementing an ensemble approach if prediction accuracy needs improvement.\n",
    "\n",
    "Explore more sophisticated deep learning architectures if you have sufficient data.\n",
    "\n",
    "Regularly update the models with new project data to maintain accuracy.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bimpredict_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
